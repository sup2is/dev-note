# 데이터 중심 애플리케이션 설계



# #1 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션

- 오늘날 많은 애플리케이션은 계산 중심과는 다르게 데이터 중심 적이다. 이는 CPU 성능이 아닌 데이터의 양, 데이터의 복잡도, 데이터의 변화 속도가 더 중요하다.

## 데이터 시스템에 대한 생각

- 이 책에서는 대부분의 소프트웨어 시스템에서 중요하게 여기는 세가지 관심사에 중점을 둔다.

`신뢰성 Reliability`

- 하드웨어나 소프트웨어 겨함. 심지어 인적 오류 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작해야 한다.

`확장성 Scalability`

- 시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 있는 적절한 방법이 있어야 한다.

`유지보수성 Maintainability`

- 시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 한다.



## 신뢰성

- 소프트웨어에서 기대하는 일반적인 기대치
  - 애플리케이션은 사용자가 기대한 기능을 수행한다.
  - 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.
  - 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.
  - 시스템은 허가되지 않은 접근과 오남용을 방지한다.
- 잘못될 수 있는 일을 결함 이라고 부르고 그 결함을 예측하고 대처할 수 있는 시스템을 내결함성 또는 탄력성을 지녔다고 말한다.
- 결함이 0일수는 없다. 하지만 특정 결함으로 인해 장애가 발생하지 않게끔 내결함성 구조를 설계하는 것이 좋다.



### 하드웨어 결함

### 소프트웨어 오류

### 인적 오류

- 사람이 미덥지 않음에도 시스템을 어떻게 신뢰성 있게 만들까에 대한 아이디어들
  - 오류의 가능성을 최소화하는 방향으로 시스템을 설계하라. 잘 설계된 추상화, API, 관리 인터페이스를 사용하면 옳은 일은 쉽게하고 잘못된 일은 막을 수 있다. 인터페이스가 지나치게 제한적이면 사람들은 좋은 점을 잊은 채 제한된 인터페이스를 피해 작업한다. 이런 시스템 설계는 올바르게 작동하게끔 균형을 맞추기가 어렵다.
  - 사람이 가장 많이 실수하는 장소에서 사람의 실수로 장애가 발생할 수 있는 부분을 분리하라. 비 프로덕션 샌드박스를 제공하라.
  - 단위 테스트부터 전체 시스템 통합 테스트와 수동 테스트까지 모든 수준에서 철저하게 테스트하라.
  - 장애 발생의 영향을 최소화하기 위해 인적 오류를 빠르고 쉽게 복수할 수 있게 하라. 예를 들어 설정 변경 내역을 rollback하고 새로운 코드를 서서히 rollout 하게 만들기
  - 성능 지표와 오류율 같은 상세하고 명확한 모니터링 대책을 마련하라.
  - 조작 교육과 실습을 시행하라.



### 신뢰성은 얼마나 중요할까?

- 비즈니스 애플리케이션에서 버그는 생산성 저하의 원인이고 전자 상거래 사이트의 중단은 많은 비용을 초래한다.
- 모든 애플리케이션은 안정적으로 작동해야 한다.



## 확장성

- 시스템이 현재 안정적으로 동작한다고 해서 미래에도 안정적으로 동작한다는 보장은 없다.
- 성능 저하를 유발하는 흔한 이유중 하나는 부하 증가다.
- 확장성을 논한다는 것은 아래와 같은 질문을 고려한다는 의미다.
  - 시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?
  - 추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?

### 부하 기술하기

- 무엇보다 시스템의 현재 부하를 간결하게 기술해야 한다. 그래야 부하 성장 질문을 논의할 수 있다.

### 성능 기술하기

- 일단 시스템 부하를 기술하면 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다.
  - 부하 매개변수를 증가시키고 시스템 자원은 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까?
  - 부하 매개변수를 증가시켰을 때 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까?



### 부하 대응 접근 방식

- 다수의 장비에 부하를 분산하는 아키텍처를 비공유(shared-nothing) 아키텍처 라고 부른다.



## 유지보수성

- 소프트웨어 비용의 대부분은 초기 개발이 아니라 지속해서 이어지는 유지보수에 들어간다는 사실은 잘 알려져 있다.
- 주의를 기울여야 할 소프트웨어 시스템 설계 원칙

`운용성`

- 운영팀이 시슽메을 원활하게 운영할 수 있게 쉽게 만들어라

`단순성`

- 시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라

`발전성`

- 엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 하례를 적용하기가 쉽다.



#### 운용성: 운영의 편리함 만들기

- "좋은 운영은 나쁜 소프트웨어의 제약을 피하는 대안이 될 수 있다. 하지만 좋은 소프트웨어라도 나쁘게 운영할 경우 작동을 신뢰할 수 없다."
- 운영 중 일부 측면은 자동화할 수 있고 또 자동화 해야 한다.
- 좋은 운영팀의 역할
  - 시스템 상태를 모니터링하고 상태가 좋지 않다면 빠르게 서비스를 복원
  - 시스템 장애, 성능 저하 등의 문제의 원인을 추적
  - 보안 패치를 포함해 소프트웨어와 플랫폼을 최신 상태로 유지
  - 다른 시스템이 서로 어떻게 영향을 주는지 확인해 문제가 생길 수 있는 변경 사항을 손상을 입히기 전에 차단
  - 미래애 발생 가능한 문제를 예측해 문제가 발생하기 전에 해결
  - 배포, 설정 관리 등을 위한 모범 사례와 도구를 마련
  - 애플리케이션을 특정 플랫폼에서 다른 플랫폼으로이동하는 등 복잡한 유지보수 태스크 수행
  - 설정 변경으로 생기는 시스템 보안 유지보수
  - 예측 가능한 운영과 안정적인 서비스 환경을 유지하기 위한 절차 정의
  - 개인 인사 이동에도 시스템에 대한 조직의 지신을 보존함
- 좋은 운영성이랑 동일하게 반복되는 태스크를 쉽게 수행하게끔 만들어 운영팀이 고부가가치 활동에 노력을 집중한다는 의미다.
- 동일 반복 태스크를 쉽게하기 위한 일
  - 좋은 모니터링으로 런타임 동작과 시스템의 내부에 대한 가시성 제공
  - 표준 도구를 이용해 자동화와 통합을 위한 우수한 지원을 제공
  - 개별 장비 의존성을 회피. 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함.
  - 좋은 문서와 이해하기 쉬운 운영 모델들 제공
  - 만족할만한 기본 동작을 제공하고 필요할 때 기본 값을 다시 정의할 수 있는 자유를 관리자에게 부여
  - 적절하게 자기 회복이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함
  - 예측 가능하게 동작하고 예기치 않은 상황을 최소화함

### 단순성: 복잡도 관리

- 복잡도가 높아지면 유지보수 비용이 증가한다.
- 단순성은 시스템의 핵심 목표여야 한다.
- 우발적 복잡도를 제거하기 위한 최상의 도구는 추상화다. 좋은 추상화는 깔끔하고 직관적인 외관 아래로 많은 세부 구현을 숨길 수 있다.



### 발전성: 변화를 쉽게 만들기

- 시스템의 요구사항은 끊임없이 할 가능성이 훨씬 크다.
- 데이터 시스템 변경을 쉽게 하고 변화된 요구사항에 시스템을 맞추는 방법은 시스템의 간단함과 추상화와 밀접한 관련이 있다.



## 정리

- 애플리케이션이 유용하려면 다양한 요구사항을 충족시켜야 한다.
- 다양한 요구사항에는 기능적 요구사항(실제로 동작하는 기능), 비기능적 요구사항(신뢰성, 확장성, 유지보수성) 이 있다.
- 신뢰성은 결함이 발생해도 시스템이 올바르게 동작하게 만든다는 의미다. 결함은 하드웨어, 소프트웨어, 사람에게 있을 수 있고 내결함성 기술은 최종 사용자에게 특정 유형의 결함을 숨길 수 있게 해준다.
- 확장성은 부하가 증가해도 좋은 성능을 유지하기 위한 전략을 의미한다. 확장성을 설명하려면 먼저 양적으로 부하와 성능을 설명하는 방법이 필요하다. 확장 가능한 시스템에서는 부하가 높은 상태에서 신뢰성을 유지하기 위해 처리 용량을 추가할 수 있다.
- 유지보수성에는 많은 측면이 있지만 유지보수성의 본질은 시스템에서 작업하는 엔지니어와 운영 팀의 삶을 개선하는 데 있다. 좋은 추상화는 복잡도를 줄이고 쉽게 시스템을 변경할 수 있게 하며 새로운 사용 사례에 적용하는데 도움이 된다. 좋은 운용성이란 시스템의 건강 상태를 잘 관찰할 수 있고 시스템을 효율적으로 관리하는 방법을 보유한다는 의미다.





# #2 데이터 모델과 질의 언어

- 각 계층은 명확한 데이터 모델을 제공해 하위 계층의 복잡성을 숨긴다.
- 데이터 모델은 그 위에서 소프트웨어가 할 수 있는 일과 할 수 없는 일에 지대한 영향을 주므로 애플리케이션에서 적합한 데이터 모델을 선택하는 작업은 상당히 중요하다.

## 관계형 모델과 문서 모델

- 오늘날 가장 잘 알려진 데이터 모델
- 데이터는 관계로 구성되고 각 관계는 순서 없는 튜플(row) 모음이다.



### NoSQL의 탄생

- NoSQL은 비관계형 데이터베이스 밋업용 인기 트위터 해시태그였지만 시간이 지나면서 Not Only SQL로 재해석 됐다.
- NoSQL의 다양한 원동력
  - 대규모 데이터셋이나 매우 높은 쓰기 처리량 달성을 관계형 데이터베이스보다 쉽게할 수 있는 뛰어난 확장성의 필요
  - 상용 데이터베이스 제품보다 무료 오픈소스 소프트웨어에 대한 선호도 확산
  - 관계형 모델에서 지원하지 않는 특수 질의 동작
  - 관계형 스키마의 제한에 대한 불만과 더욱 동적이고 표현력이 풍부한 데이터 모델에 대한 바람
- 관계형, 비관계형 데이터베이스를 함께사용하는 개념을 다중 저장소 지속성(polyglot persistence) 이라 한다.



### 객체 관계형 불일치

- 데이터를 관계형 테이블에 저장하려면 애플리케이션 코드와 데이터 베이스 모델 객체 사이에 거추장스로운 전환 계층이 필요하다. 임피던스 불일치(impedance mismatch)
- 액티브레코드나 하이버네이트 같은 ORM 프레임워크는 전환 계층에 필요한 상용구 코드의 양을 줄이지만 두 모델 간의 차이를 완벽히 숨길 수는 없다.
- 이력서같은 데이터 구조는 모든 내용을 갖추고 있는 문서라서 JSON 표현에 매우 적합하다.
- 관계형 데이터베이스의 다중 테이블 스키마보다 JSON 표현이 더 나은 지역성을 갖는다.



### 다대일과 다대다 관계

- ID를 사용하는 장점으로 ID 자체는 아무런 의미가 없기 때문에 변경할 필요가 없다.
- 중복된 데이터를 정규화하려면 다대일 관계가 필요한데 다대일 관계는 문서 모델에 적합하지 않다.
- 문서 데이터베이스는 조인에 대한 지원이 보통 약하다.



### 문서 데이터베이스는 역사를 반복하고 있나?

#### 네트워크 모델

#### 관계형 모델

#### 문서 데이터베이스와의 비교

### 관계형 데이터베이스와 오늘날의 문서 데이터베이스

- 관계형 데이터베이스와 문서 데이터베이스의를 비교하는 경우 내결함성과 동시성 처리를 포함해 고려해야 할 차이점이 많이 있다.
- **문서 데이터 모델을 선호하는 주요 이유는 스키마 유연성, 지역성에 기인한 더 나은 성능이다**
- **관계형 모델은 조인, 다대일, 다대다 관계를 더 잘 지원함으로써 문서 데이터 모델에 대항한다.**

#### 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까?

- 애플리케이션에서 데이터가 문서와 비슷한 구조라면 문서 모델을 사용하는 것이 좋다 (일대다 관계 트리로 보통 한 번에 전체 트리를 적재)
- 문서 모델은 중첩 항목을 바로 참조할 수 없어서 계층별로 탐색해야 하지만 문서가 너무 깊게 중첩되지 않으면 일반적으로 문제가 되지는 않는다.
- 애플리케이션에서 다대다 관계를 사용한다면 문서 모델은 매력이 떨어지게 된다.
- 일반적으로 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 만드는지 말할 수 없다. 데이터 항목 간에 존재하는 관계 유형에 따라 다르다.
- 상호 연결이 많은 데이터의 경우 문서 모델은 곤란하고 관계형 모델은 무난하다.

#### 문서 모델에서의 스키마 유연성

- 대부분의 문서 데이터베이스와 관계형 데이터베이스에서 지원하는 JSON은 문서의 데이터에 어떤 스키마를 강요하지는 않는다.
- 스키마가 없다는 뜻은 임의 키와 값을 문서에 추가할 수 있고 읽을 때 클라이언트는 문서에 포함된 필드의 존재 여부를 보장하지 않는다는 의미다.
- 스키마리스 방식은 컬렉션 안의 항목이 어떤 이유로 모두 동일한 구조가 아닐 때 유리하다
- 이런 경우 스키마는 득보다 실이 많다.
  - 다른 여러 유형의 오브젝트가 있고 각 유형의 오브젝트별로 자체 테이블에 넣는 방법은 실용적이지 않다.
  - 사용자가 제어할 수 없고 언제나 변경 가능한 외부 시스템에 의해 데이터 구조가 결정된다.

#### 질의를 위한 데이터 지역성

- 한번에 많은 문서에 접근해야 할때 저장소 지역성을 활용하면 성능 이점이 있다.
- 지역성의 이점은 한 번에 해당 문서의 많은 부분을 필요로 하는 경우에만 적용된다.
- 데이터베이스는 문서의 작은 부분만 접근해도 전체 문서를 적재해야 하기 때문에 큰 문서는 낭비일 수 있고 이러한 이유로 일반적으로 문서의 크기를 아주 작게 유지하라고 권장한다.
- 지역성을 위해 데이터를 함꼐 그룹화하는 개념은 문서 모델에만 국한되지 않는다. 구글의 스패너 데이터베이스, 오라클의 다중 테이블 색인 클러스터 테이블, 빅테이블 데이터 모델의 칼럼 패밀리 개념(카산드라 Hbase)이 지역성 관리와 유사한 목적이 있다.



#### 문서 데이터베이스와 관계형 데이터베이스의 통합

- 많은 DBMS가 JSON 문서에 대한 지원 기능을 제공하고 있다.
- 관계형 데이터베이스와 문서 데이터베이스는 시간이 지남에 따라 점점 더 비슷해지고 있다.
- 관계형과 문서의 혼합 모델은 미래 데이터베이스들이 가야 할 올바른 길이다.



## 데이터를 위한 질의 언어

- 명령형 언어는 특정 순서로 특정 연산을 수행하게끔 컴퓨터에게 지시한다.
- SQL같은 선언형 질의 언어는 목표를 달성하기 위한 방법이 아니라 알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환잘지를 지정하기만 하면 된다.
- 어떤 색인과 어떤 조인 함수를 사용할지, 질의의 다양한 부분을 어떤 순서로 실행할지를 결정하는 일은 데이터베이스 시스템의 질의 최적화기가 할 일이다.
- SQL이 기능적으로 더 제한적이라는 사실은 데이터베이스에게 자동으로 최적화할 수 있는 여지를 더 많이 준다는 의미다.
- 선언형 언어는 결과의 패턴만 지정하기 때문에 병렬 실행으로 더 빨라질 가능성이 크다.



### 웹에서의 선언형 질의

- 웹 브라우저에서 선언형 CSS 스타일을 사용하는 편이 자바스크립트에서 명령형으로 스타일을 다루기보다 훨씬 낫다.

### 맵리듀스 질의

- 맵리듀스는 많은 컴퓨터에서 대량의 데이터를 처리하기 위한 프로그래밍 모델로 구글에 의해 널리 알려졌다.
- 몽고db와 카우치db를 포함한 일부 nosql 데이터 저장소는 제한된 형태의 맵리듀스를 지원한다.
- 주로 많은 문서를 대상으로 읽기 전용 질의를 수행할 때 사용한다. 자세한 내용은 10장에서

## 그래프형 데이터 모델

- 애플리케이션이 주로 일대다 관계이거나 레코드 간 관계가 없다면 문서 모델이 적합하다.
- 애플리케이션이 다대다 관계가 매우 일반적이라면 관계형 모델은 복잡해질 수 있으므로 그래프로 데이터를 모델링하기 시작히는 편이 더 자연스럽다.
- 그래프는 정점과 간선으로 이루어져있고 많은 유형의 데이터를 그래프로 모델링할 수 있다.
  - 소셜 그래프
    - 정점은 사람이고 간선은 사람들이 서로 알고 있음을 나타낸다.
  - 웹 그래프
    - 정점은 웹 페이지고 간선은 다른 페이지에 대한 HTML링크를 나타낸다.
  - 도로나 철도 네트워크
    - 정점은 교차로이고 간선은 교차로 간 도로나 철로 선을 나타낸다.



### 속성 그래프

- 속성 그래프 모델에서 각 정점은 다음과 같은 요소로 구성된다.
  - 고유한 식별자
  - 유출(outgoing) 간선 집합
  - 유입(incoming) 간선 집합
  - 속성 컬렉션(키-값 쌍)
- 각 간선은 다음과 같은 요소로 구성된다.
  - 고유한 식별자
  - 간선이 시작하는 정점(꼬리 정점)
  - 간선이 끝나는 정점(머리 정점)
  - 두 정점 간 관계 유형을 설명하는 레이블
  - 속성 컬렉션(키-값 쌍)
- 그래프는 발전성이 좋아서 애플리케이션에 기능을 추가하는 경우 애플리케이션의 데이터 구조르 변경을 수용하게끔 그래프를 쉽게 확장할 수 있다.

### 사이퍼 질의 언어

- 사이퍼는 속성 그래프를 위한 선언형 질의 언어로 neo4j 그래프 데이터베이스용으로 만들어졌다.

### SQL의 그래프 질의

### 트리플 저장소와 스파클

### 초석: 데이터 로그

## 정리

- 데이터 모델은 광범위한 주제다.
- 역사적으로 데이터를 하나의 큰 트리로 표현하려고 노력했지만 다대다 관계를 표현하게아는 트리구조가 적절하지 않았다.
- 최근 개발자들은 관계형 모델에도 적합하지 않은 애플리케이션이 있다는 사실을 발견했다
- 새롭게 등장한 비관계형 데이터저장소 NoSQL은 다음과 같은 두 가지 주요 갈래가 있다.
  1. 문서 데이터베이스는 데이터가 문서 자체에 포함돼 있으면서 하나의 문서와 다른 문서 간 관계가 거의 없는 사용 사례를 대상으로 한다.
  2. 그래프 데이터베이스는 문서 데이터베이스와는 정 반대로 모든 것이 잠재적으로 관련 있다는 사용 사례를 대상으로 한다.
- 문서, 관계형, 그래프 모두 각기 목적에 맞는 다양한 시스템을 보유해야 한다.
- 문서 및 그래프 데이터베이스가 가진 공통점 중 하나는 일반적으로 스키마를 강제하지 않아 변화하는 요구사항을 맞춰 애플리케이션을 쉽게 변경할 수 있다는 점이다. 
- 각 데이터 모델은 고유한 질의 언어나 프레임워크를 제공한다.





# #3 저장소와 검색

- 대개 애플리케이션 개발자가 처음부터 자신의 저장소 엔진을 구현하기 보다는 사용 가능한 여러 저장소 엔진 중에 애플리케이션에 적합한 엔진을 선택하는 작업이 필요하다.

## 데이터베이스를 강력하게 만드는 데이터 구조

- 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터구조가 필요하다. 바로 색인이다.
- 색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.
- 이 메타데이터는 이정표 역하을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다.
- 색인 작업은 데이터베이스의 내용에는 영향을 미치지 않고 단지 질의 성능에만 영향을 준다. 하지만 데이터를 쓸 떄마다 매번 색인도 갱신해야 하기 때문에 쓰기 속도를 느리게 만든다.
- 색인을 잘 선택했다면 읽기 질의 속도가 향상된다. 하지만 모든 색인은 쓰기 속도를 떨어트린다. 이것은 저장소 시스템에서 중요한 트레이드오프다.

### 해시 색인

- 키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 dictionary 타입과 매우 유사하다.

- 비트캐스크는 해시 맵을 전부 메모리에 유지하기 떄문에 사용 가능한 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기, 쓰기를 보장한다.

- 비트캐스크 같은 저장소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다. (키당 쓰기 수가 많지만 메모리에 모든 키를 보관할 수 있는 경우)

- 하지만 실제로 구현하려면 파일 형식, 레코드 삭제, 고장 복구, 부분적으로 레코드 쓰기, 동시성 제어 등등 세부적으로 많은 사항을 고려해야 한다.

  

### SS테이블과 LSM 트리

#### SS테이블 생성과 유지

#### SS테이블에서 LSM 트리 만들기

#### 성능 최적화

### B 트리

- B트리는 70년대 등장했고 여전히 거의 대부분의 관계형 데이터베이스에서 표준 색인 구현으로 B 트리를 사용하고 NoSQL에서도 사용한다.
- 한 페이지는 B 트리의 루트로 지정되고 색인에서 키를 찾으려면 루트에서 시작한다.
- 범위를 계속 좁혀가면서 최종적으로 개별 키(리프 페이지)를 포함하는 페이지에 도달한다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.
- 이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다.
- n 개의 키를 가진 B 트리는 깊이가 항상 O(log n) 이다.

#### 신뢰할 수 있는 B 트리 만들기

- B트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 페이지를 덮어 쓰더라도 페이지를 가리키는 참조는 모두 온전하게 남는다.
- 데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만들려면 일반적으로 디스크 상에 쓰기 전 로그(redo log)라고 하는 데이터 구조를 추가해 B 트리를 구현한다.
- 동시성 제어는 보통 래치로 트리의 데이터 구조를 보호한다.

#### B 트리 최적화

### B 트리와 LSM 트리 비교

- 경험적으로 LSM 트리는 보통 쓰기에서 더 빠르고 B 트리는 읽기에서 더 빠른다고 여긴다.

#### LSM 트리의 장점

#### LSM 트리의 단점

### 기타 색인 구조

#### 색인 안에 값 저장하기

- 색인에서 키는 질의가 검색하는 대상이지만 값은 실제로우거나 저장된 로우를 가르키는 참조다.
- 저장된 로우를 가르키는 경우 저장된 곳을 힙파일이라고 하고 특정 순서 없이 데이터를 저장한다.
- 힙 파일 접근 방식은 키를 변경하지 않고 값을 갱신할 때 효율적이다.
- 어떤 상황에서는 색인 안에 바로 색인된 로우를 저장하는 편이 바람직한데 이를 클러스터드 색인 이라고 한다. MySQL의 InnoDbB의 기본키는 언제나 클러스터드 색인이고 보조 색인은 기본키를 참조한다.
- 클러스터드 색인과 비클러스터드 색인 사이의 절충안을 커버링 색인이라고하고 이 색인은 색인 안에 테이블의 칼럼 일부를 저장하는 것이다.
- 클러스터드 색인과 커버링 색인은 읽기 성능을 높일 수 있지만 추가적인 저장소가 필요하고 쓰기 과정에 오버헤드가 발생한다.

#### 다중 칼럼 색인

- 다차원 색인은 한 번에 여러 칼럼에 질의하는 조금 더 일반적인 방법이다.
- 특히 지리 공간 데이터에 중요하게 사용된다.

#### 전문 검색과 퍼지 색인

- 위에서 설명한 색인으로는 철자가 틀린 단어와 같이 유사한 키에 대해서는 검색을 할 수 없다.
- 전문 검색 엔진은 일반적으로 특정 단어를 검색할 때 해당 단어의 동의어로 질의를 확장한다.

#### 모든 것을 메모리에 보관

- 인메모리 데이터베이스가 재시작 되는 경우 특수 하드웨어를 사용하지 않는다면 디스크나 네트워크를 통해 복제본에서 상태를 다시 적재해야 한다.

## 트랜잭션 처리나 분석?

- 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾고 레코드는 사용자 입력을 기반으로 삽입되거나 갱신된다. 이런 접근 패턴을 온라인 트랜잭션 처리 (Online Transcation Processiong. OLTP) 라고 한다.
- 데이터베이스는 데이터 분석에도 점점 더 많이 사용하기 시작했다. 이런 데이터베이스의 사용 패턴을 트랜잭션 처리와 구별하기 위해 온라인 분석 처리(Online Analytic Processing. OLAP) 라고 한다.
- 초기에는 트랜잭션 처리와 분석 질의를 위해 동일한 데이터베이스를 사용했지만 시스템 분석 목적으로 사용하는 개별 데이터베이스를 사용했다 이것을 데이터 웨어하우스라고 부른다.

### 데이터 웨어하우징

- 트랜잭션이 필요한 사업은 일반적으로 높은 가용성과 낮은 지연 시간의 트랜잭션 처리를 기대한다. 하지만 분석질의는 비용이 높기 때문에 실행되는 트랜잭션의 성능을 저하시킬 가능성이 있다.
- 데이터 웨어하우스는 분석가들이 트랜잭션 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스다.
- 데이터 웨어하우스는 회사 내의 모든 다양한 트랜잭션 사업 시스템에 있는 데이터의 읽기 전용 복사본이다.
- 데이터는 OLTP 데이터베이스에서 추출하고 분석 친화적인 스키마로 변환하고 정제된 데이터를 데이터 웨어하우스에 적재한다.
- 데이터 웨어하우스로 데이터를 가져오는 과정을 ELT(Extract Transform Load) 라고 한다.

#### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

- SQL은 일반적으로 분석 질의에 적합하기 때문에 데이터 웨어하우스의 데이터 모델은 가장 일반저인 관계형 모델을 사용한다.
- OLAP와 OLTP 모두 SQL 질의 인터페이스를 지원하기 떄문에 비슷해보이지만 각각 매우 다른 질의 패턴에 맞체 괴적화 됐기 때문에 이제 다수의 데이터베이스 벤더는 트랜잭션 처리와 분석 작업부하 양쪽 모두 지원하기 보다는 둘 중 하나를 지원하는데 중점을 둔다.

### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

- 분석에서는 데이터 모델의 다양성이 트랜잭션 처리영역보다 훨씬 적다.
- 많은 데이터 웨어하우스는 별 모양 스키마로 알려진 상당히 정형화된 방식을 사용한다.
- 스키마 중심에는 fact table이 있다.
- 이 fact table은 개별 이벤트를 담는다. ex 웹 페이지 뷰, 사용자 클릭 등등
- 별 모양 스키마인 이유는 사실 테이블이 중심에 있고 여러 테이블로 둘러싸고 있다는 사실에서 비롯됐다. 이 템플릿의 변형으로 눈꽃송이 모양 스키마도 있다.
- 일반적인 데이터 웨어하우스에서 테이블의 보통 폭이 매우 높다 100개 이상의 칼럼 + @ 

## 칼럼 지향 저장소

- 사실 테이블은 칼럼이 보통 100개 이상이지만 일반적인 데이터 웨어하우스 질의는 한 번에 4개 또는 5개 칼럼만 접근한다.
- 칼럼 지향 저장소의 기본개념은 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다.
- 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다.
- 이 방식을 사용하면 작업량이 많이 줄어든다.

### 칼럼 압축

- 질의에 필요한 칼럼을 디스크에서 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 더 줄일 수 있다.
- 칼럼 지향 저장소는 대개 압축에 적합하다.
- 각 칼럼의 값에 많은 값이 반복되면 압축에 매우 좋다.
- 데이터웨어하우스에서는 비트맵 부호화를 사용해서 압축을 시도한다.
- 보통 칼럼의 고유 값의 수는 로우 수의 비해 적기때문에 n개의 고유 값을 가진 칼럼을 가져와 n개의 개별 비트맵으로 변환할 수 있다.



#### 메모리 대역폭과 벡터화 처리

- 수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다.
- 이 병목 외에도 분석용 데이터베이스 개발자는 메인 메모리에서 CPU 캐시로 가는 대역폭을 효육적으로 사용하고 CPU 명령 처리 파이프라인에서 분기 예측 실패와 버블을 피하며 최신 CPU에서 단일 명령 다중 데이터 명령을 신중하게끔 신경써야 한다.

### 칼럼 저장소의 순서 정렬

#### 다양한 순서 정렬

### 칼럼지향 저장소에 쓰기

- 칼럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 쓰기를 어렵게 한다는 단점이 있다.
- B트리 같은 제자리 갱신 접근 상식은 압축된 칼럼에서 사용이 불가능하다.
- LSM 트리처럼 모든 쓰기는 먼저 인메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 충분한 쓰기를 모으면 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다.

### 집계: 데이터 큐브와 구체화 뷰

## 정리

- 고수준에서 저장소 엔진은 트랜잭션 처리 최적화(OLTP)와 분석 최적화(OLAP)라는 큰 두가지 범주로 나눈다.

`OLTP 시스템`

- 사용자 대면이기 떄문에 대량의 요청을 받을 수 있다.
- 부하를 처리하기 위해 보통 애플리케이션이 각 질의마다 작은 수의 레코드만 다룬다.
- 애플리케이션은 키의 일부만 사용하는 레코드를 요청하고 저장소 엔진은 요청한 키의 데이터를 찾기 위해 색인을 사용한다.
- 이 경우는 대개 디스크 탐색이 병목이다.

`데이터 웨어하우스와 유사한 분석 시스템 (OLAP)`

- 최종 사용자가 아닌 비즈니스 분석가가 주로 사용하기 때문에 덜 알려져 있다.
- OLTP 시스템보다 훨씬 더 적은 수의 질의를 다루지만 각 질의는 대개 매우 다루기 어렵고 짧은 시간에 수백만 개의 레코드를 스킨해야 한다.
- 이 경우 일반적으로 디스크 대역폭이 병목이다.
- 칼럼 지향 저장소는 이런 종류의 작업부하를 처리할 때 사용 가능한 날로 인기가 높아지고 있는 솔루션이다.

`OLTP 측면에서 두 가지 주요한 관점`

- 로그 구조화 관점에서 파일에 추가와 오래된 파일의 삭제만 허용하고 한 번 쓰여진 파일은 절대 갱신하지 않는다. 비트캐스크, SS테이블, LSM트리, 카산드라, Hbase, 루씬 등이 이 그룹에 속한다
- 제자리 갱신 관점에서 덮어쓰기 할 수 있는 고정 크기 페이지의 셋으로 디스크를 다룬다. 이 관점에서 가장 큰 예가 B트리다. B트리는 주요 관계형 데이터베이스와 많은 비정형 데이터베이스에서도 사용한다.





# #4 부호화와 발전

- 애플리케이션은 필연적으로 시간이 지남에 따라 변한다.
- 애플리케이션의 기능을 변경하려면 저장하는 데이터 타입이나 스키마도 같이 변경되는데 대규모 애플리케이션에서 코드 변경은 대개 즉시 반영할 수 없다.
- 시스템이 계속 원활하게 실행되게 하려면 양방향으로 호환성을 유지해야 한다.
  - 하위 호환성: 새로운 코드는 예전 코드가 기록한 데이터를 읽을 수 있어야 한다.
  - 상위 호환성: 예전 코드는 새로운 코드가 기록한 데이터를 읽을 수 있어야 한다.
- 하위 호환성은 일반적으로 어렵지 않지만 상위 호환성은 예쩐 버전의 코드가 새 버전의 코드에 의해 추가된 것을 무시할 수 있어야 하므로 다루기 더 어렵다.

## 데이터 부호화 형식

- 데이터를 파일에 쓰거나 네트워크를 통해 전송하려면 스스로를 포함한 일련의 바이트열의 형태로 부호화해야 한다.
- 포인터는 다른 프로세스가 이해할 수 없으므로 이 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와는 상당히 다르다.
- 따라서 두 가지 표현 사이에 일종의 전환이 필요한데 인메모리 표현에서 바이트열로 전환을 마샬링이라고 하고 그 반대를 언마샬링이라고 한다.

### 언어별 형식

- 프로그래밍 언어에 내장된 마샬링/언마샬링 라이브러리는 최사한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있기 때문에 매우 편리하지만 심각한 문제점 또한 많다.
  - 마샬링/언마샬링은 보통 특정 프로그래밍 언어와 묶여 있어 다른 언어에서 데이터를 읽기는 매우 어렵다.
  - 동일한 객체 유형의 데이터를 복원하려면 언마샬링 과정이 임의의 클래스를 인스턴스화할 수 있어야 한다. 종종 보안의 문제가 되는데 공격자가 임의의 바이트열을 언마샬링 할 수 있는 애플리케이션을 얻을 수 있으면 임의의 클래스를 인스턴스화할 수 있고 공격자가 원격으로 임의의 코드를 실행하는 것과 같은 끔찍한 일이 발생할 수 있다.
  - 효율성도 종종 생각해야한다. 자바의 내장 마샬링/언마샬링은 성능이 좋지 않다.

### JSON과 XML, 이진 변형

- JSON과 XML, CVS는 각각 장점과 단점이 명확하지만 다양한 용도에 사용하기 충분하다.

#### 이진 부호화 

### 스리프트와 프로토콜 버퍼

- 아파치 스리프트와 프로토콜 버퍼는 같은 원리를 기반으로 한 이진 부호화 라이브러리다.
- 스리프트와 프로토콜 모두 스키마가 필요하다.

```

# 아파치 스리프트
struct Phone {
  1: i32 id,
  2: string number,
  3: PhoneType type 
}


# 프로토콜 버퍼
message Person{
  string name = 1;
  int32 age=2;
  string email=3;
}

```

- 스리프트와 프로토콜 버퍼는 각각 여기서 본 것처럼 스키마 정의를 사용해 코드를 생성하는 도구가 있다. 이 도구는 다양한 프로그래밍 언어로 스키마를 구현한 클래스를 생성한다.
- 스리프트는 바이너리프로토콜과 컴팩트프로토콜이라는 두 가지 다른 이진 부호화형식이 있다.

#### 필드 태그와 스키마 발전

- 스키마는 필연적으로 시간이 지남에 따라 변한다 이를 스키마 발전이라고 부른다.

#### 데이터타입과 스키마 발전

### 아브로

- 아브로는 스리프트가 하둡의 사용 사례에 적합하지 않아 2009년 하둡의 하위 프로젝트로 시작했다.
- 아브로도 부호화할 데이터 구조를 지정하기 위해 스키마를 사용한다.
- 아브로에는 두 개의 스키마 언어가 있다. 하나는 사람이 편집할 수 있는 아브로 IDL, 하나는 기계가 더 쉽게 읽을 수 있는 JSON 기반 언어다.

```
record Person {
	string userName;
	union { null, long} favoritNumber = null;
	array<string> interests;
}


{
	"type": "recode",
	"name": "person",
	"fields" : [
		{"name": "userName", type:"string"},
		...
	]
}
```

#### 쓰기 스키마와 읽기 스키마

- 애플리케이션이 파일이나 데이터베이스에 쓰기 위해 또는 네트워크 전송 등의 목적으로 어떤 데이터를 아브로로 부호화하길 원한다면 알고 있는 스키마 버전을 사용해 데이터를 부호화한다. 이를 쓰기 스키마 라고 한다.
- 애플리케이션이 파일이나 데이터베이스에서 또는 네트워크로부터 수신 등으로 읽은 어떤 데이터를 복호화하길 원한다면 데이터가 특정 스키마로 복호화하길 기대한다. 이 스키마를 읽기 스키마라고 한다.
- 아브로의 핵심 아이디어는 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며 단지 호환 가능하면 된다는 것이다.
- 데이터를 복호화할 때 아브로 라이브러리는 쓰기 스키마와 읽기 스키마를 함께 살펴본 다음 쓰기 스키마에서 읽기 스키마로 데이터를 변환해 그 차이를 해소하낟.
- 스키마 해석에서는 이름으로 필드를 일치시키기 때문에 필드의 순서가 달라도 되고 데이터를 읽는 코드가 읽기스키마에는 없고 쓰기 스키마에 존재하는 필드면 이 필드는 무시한다. 그 반대라면 읽기스키마에 선언된 기본값으로 채운다.

#### 스키마 발전 규칙

- 아브로에서 상위호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미한다. 반대로 하위 호환성은 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음을 의미한다.

#### 그러면 쓰기 스키마는 무엇인가?

#### 동적 생성 스키마

#### 코드 생성과 동적 타입 언어

### 스키마의 장점

- 프로토콜 버퍼, 스리프트, 아브로는 스키마를 사용해 이진 부호화 형식을 기술한다.
- 이 스키마언어는 xml 스키마나 json 스키마보다 훨씬 간단하며 더 자세한 유효성 검사 규칙을 지원한다.
- 부호화된 데이터에서 필드 이름을 생략할 수 있기 때문에 다양한 "이진 JSON" 변형보다 크기가 훨씬 작을 수 있다.
- 스키마는 유용한 문서화 형식이다. 복호화를 할 때 스키마가 필요하기 떄문에 스키마가 최신 상태인지를 확신할 수 있다.
- 스키마 데이터베이스를 유지하면 스키마 변경이 적용되기 전에 상위 호환성과 하위 호환성을 확인할 수 있다.
- 정적 타입 프로그래밍 언어 사용자에게 스키마로부터 코드를 생성하는 기능은 유용하다. 컴파일 시점에 타입 체크를 할 수 있기 때문이다.
- 요약하면 스키마 발전은 스키마리스 또는 읽기스키마 JSON 데이터베이스가 제공하는 것과 동일한 종류의 유연성을 제공하며 데이터나 도구 지원도 더 잘 보장한다.

## 데이터플로 모드

- 데이터플로는 매우 추상적인 개념으로서 하나의 프로세스에서 다른 프로세스로 데이터를 전달하는 방법은 아주 많다.

### 데이터베이스를 통한 데이터플로

- 데이터베이스에 기록하는 프로세스는 데이터를 부호화하고 데이터베이스에서 읽는 프로세스는 데이터를 복호화한다.
- 데이터베이스 내 값이 새로운 버전의 코드로 기록된 다음 현재 수행중인 예전 버전의 코드로 그 값을 읽을 가능성이 있다.

#### 다양한 시점에 기록된 다양한 값

#### 보관 저장소

### 서비스를 통한 테이터플로: REST와 RPC

- 서버와 클라이언트가 사용하는 데이터 부호화는 서비스 API의 버전 간 호환이 가능해야 한다.

#### 웹 서비스

#### 원격 프로시저 호출(RPC) 문제

- RPC 모델은 원격 네트워크 서비스 요청을 같은 프로세스 안에서 특정 프로그래밍 언어의 함수나 메서드를 호출하는 것과 동일하게 사용 가능하게 해준다. (이런 추상화를 위치 투명성이라 한다.)
- 로컬함수 호출은 예측이 가능하지만 네트워크 요청은 예측이 어렵다. 따라서 다양한 네트워크 문제를 함께 고려해야 한다.
  - 네트워크 타임아웃에 대한 처리
  - 해당 RPC가 멱등성을 보장하는지에 대한 고려
  - 네트워크 지연시간에 대한 고려
  - 로컬함수에서는 참조를 로컬 메모리의 객체에 효율적으로 전달할 수 있지만 네트워크로 요청하는 경우 모든 매개변수는 바이트열로 부호화해야한다. 이 때 큰 객체라면 문제가 될 수 있다.

#### RPC의 현재 방향

- gRPC, 피네글, Rest.li 등등 다양한 RPC 프레임워크가 개발됐다.
- 피네글과 Rest.li는 실패할지도 모를 비동기 작업을 캡슐화 하기 위해 퓨처를 사용한다.
- gRPC는 하나의 요청과 하나의 응답뿐만 아니라 시간에 따른 일련의 요청과 응답으로 구성된 스트림을 지원한다.

#### 데이터 부호화와 RPC의 발전

- 발전성이 있으려면 RPC 클라이언트와 서버를 독립적으로 변경하고 배포할 수 있어야 한다.

### 메시지 전달 데이터플로

- REST와 RPC는 하나의 프로세스가 네트워크를 통해 다른 프로세스로 요청을 전송하고 가능한 빠른 응답을 기대하는 방식이다.
- 데이터베이스는 하나의 프로세스가 부호화한 데이터를 기록하고 다른 프로세스가 언젠가 그 데이터를 다시 읽는 방식을 사용한다. 
- 메시지를 직접 네트워크 연결로 전송하지 않고 임시로 메시지를 저장하는 메시지 브로커나 메시지 지향 미들웨어라는 중간 단계를 거쳐 전송하는 비동기 메시지 전달 시스템이 있다.
- 메시지 브로커를 사용하는 방식의 장점
  - 수신자가 사용 불가능하거나 과부하 상태라면 메시지 브로커가 버퍼처럼 동작할 수 있기 때문에 시스템 안정성이 향상된다.
  - 죽었던 프로세스에 메시지를 다시 전달할 수 있기 때문에 메시지 유실을 방지할 수 있다.
  - 송신자가 수신자의 IP 주소나 포트 번호를 알 필요가 없다.
  - 하나의 메시지를 여러 수신자로 전송할 수 있다.
  - 논리적으로 송신자는 수신자와 분리된다. 송신자는 메시지를 publish 할 뿐이고 누가 consume 하는지 상관하지 않는다.
- 메시지 전달 통신은 일반적으로 단방향이라는 점이 RPC와 다르다.

#### 메시지 브로커

- 과거에는 팁코, IBM 웹스피어. 요즘에는 Rabbit MQ, 아파치 카프카 같은 오픈소스 구현이 대중화 됐다.
- 일반적으로 프로세스 하나가 메시지를 이름이 지정된 큐나 토픽으로 전송하고 브로커는 해다 큐나 토픽 하나 이상의 소비자 또는 구독자에게 메시지를 전달한다.
- 메시지 브로커는 보통 특정 데이터 모델을 강요하지 않는다.
- 메시지는 일부 메타데이터를 가진 바이트열이므로 모든 부호화 형식을 사용할 수 있다.
- 부호화가 상하위 호환성을 모두 가진다면 메시지 브로커에서 게시자와 소비자를 독립적으로 변경해 임의 순서로 배포할 수 있는 유연성을 얻게 된다.

#### 분산 액터 프레임워크

- 액터 모델은 단일 프로세스 안에서 동시성을 위한 프로그래밍 모델이다.
- 스레드를 직접 처리하는 대신 로직이 액터에 캡슐화 된다.
- 보통 각 액터는 하나의 클라이언트나 엔티티를 나타낸다.
- 액터는 로컬 상태를 가질 수 있고 비동기 메시지의 송수신으로 다른 액터와 통신한다.
- 액터는 메시지 전달을 보장하지 않는다.
- 인기있는 분산 액터 프레임워크
  - 아카
  - 올리언스
  - 얼랭

## 정리

- 특히 많은 서비스가 새로운 버전의 서비스를 동시에 모든 노드에 배포하는 상식보다 한 번에 일부 노드에만 서서히 배포하는 순회식 업그레이드가 필요하다.
- 순회식 업그레이드는 정지 시간 없이 새로운 버전의 서비스를 출시 가능하게 하고 배포를 덜 위험하게 만든다.
- 이런 속성은 애플리케이션 변경을 쉽게할 수 있는 발전성에 도움이 많이 된다.
- 시스템을 흐르는 모든 데이터는 하위 호환성과 상위 호환성을 제공하는 방식으로 부호화해야 한다.
- 다양한 데이터 부호화 형식과 호환성 속성
  - 프로그래밍 언어에 특화된 부호화는 단일 프로그래밍 언어로 제한되며 상위 호환성과 하위 호환성을 제공하지 못하는 경우가 종종 있다.
  - JSON, XML 같은 텍스트 형식은 널리 사용딘다. 이들 간 호환성은 이 형식들을 사용하는 방법에 달려있다. 선택적 스키마 언어가 있으면 때로는 유용하고 떄로는 방해가 된다. 이 형식들은 데이터타입에 대해 다소 모호한 점이 있기 때문에 숫자나 이진 문자열과 같은 항목은 주의해야 한다.
  - 스리프트 프로토콜 버퍼, 아브로 같은 이진 스키마 기반 형식은 짧은 길이로 부호화되며 명확하게 정의된 상위 호환성과 하위 호환성의 맥락에서 효율적인 부호화를 지원한다. 이러한 스키마는 정적 타입 언어에서 문서와 코드 생성에 유용하지만 사람이 읽기 위해서는 복호화해야한다는 단점이 있다.
- 데이터 부호화의 중요성에 대한 여러 시나리오
  - 데이터베이스에 기록하는 프로세스가 부호화하고 데이터베이스에서 읽는 프로세스가 복호화하는 데이터베이스
  - 클라이언트가 요청을 부호화하고 서버는 요청을 복호화하고 응답을 부호화하고 최정적으로 클라이언트가 응답을 복호화 하는 RPC와 REST
  - 송신자가 부호화하고 수신자가 복호화하는 메시지를 서로 전송해서 노드 간 통신하는 비동기 메시지 전달 (메시지 브로커, 액터)





# #5 복제

- 복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본은 유지한다는 의미다.
- 데이터 복제가 필요한 이유
  - 지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.
  - 시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 해 가용성을 높인다.
  - 읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.
- 복제에서 모든 어려움은 복제된 데이터의 변경 처리에 있다. 변경이 없으면 복제는 쉽다.
- 노드간 변경을 복제하기 위한 세 가지 인기있는 알고리즘
  - 단일 리더 (leaderless)
  - 다중 리더 (multi-leader)
  - 리더 없는 (leaderless)





## 리더와 팔로워

- 데이터베이스의 모든 쓰기는 모든 복제 서버에서 처리되어야 한다.
- 이 문제를 해결하기 위한 가장 일반적인 해결책은 리더 기반 복제(master/slave)다.
- 쓰기요청은 리더에서 이루어지고 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 데이터 변경을 복제 로그나 변경 스트림의 일부로 팔로워에게 전송한다.
- 리더기반 복제는 다양한 저장소, rdb, nosql, queue 시스템 등등 많은 곳에서 사용한다.

### 동기식 대 비동기식 복제

- 복제 시스템의 중요한 세부 사항은 복제가 동기식으로 발생하는지 비동기식으로 발생하는지 여부다.
- 동기식 복제의 장점은 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다. 단점은 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없다. -> 동기 팔로워의 장애가 치명적이다.
- 모든 팔로워를 동기식으로 지정할 수 없기 때문에 리더1, 동기1, 비동기n으로 구성하고 동기서버가 죽으면 n개의 비동기서버중 한 개의 서버가 동기식 서버가된다. 항상 리더1, 동기1 의 형태를 구성하므로 이런 설정을 반동기식 이라고 한다.
- 위와 같이 설정하면 리더가 잘못되어 비동기 팔로워에 대한 데이터 유실이 발생했을 때도 동기 서버가 한개 있음을 보장하기 때문에 데이터 유실이 없다.
- 비동기식 복제는 내구성을 약화시키기 때문에 나쁜 트레이드오프같지만 그럼에도 많은 팔로워가 있다면 비동기식 복제를 널리 사용한다.



### 새로운 팔로워 설정

### 노등 중단 처리

#### 팔로워 장애: 따라잡기 복구

- 각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다.
- 장애가 난 경우 보관된 로그에서 결함이 발생하기 전에 처리한 마지막 트랜잭션을 알아내고 연결이 끊어진 동안 발생한 데이터 변경을 모두 요청할 수 있다.



#### 리더 장애: 장애 복구

- 팔로워 중 하나를 새로운 리더로 승격시켜야 한다. 이 과정을 장애 복구라 한다.
- 장애복구는 수동 또는 자동으로 진행한다.
- 자동 장애 복구는 아래와 같은 과정을 갖는다.
  - 리더가 장애인지 판단한다.
  - 새로운 리더를 선택한다.
  - 새로운 리더 사용을 위해 시스템을 설정한다.
- 자동 장애 복구는 여러가지 변수가 있기 때문에 수동으로 장애 복구를 수행하는 방식을 선호한다.



### 복제 로그 구현

#### 구문 기반 복제

- 리더는 모든 쓰기 요청(statement)를 기록하고 쓰기를 실행한 다음 구문 로그를 팔로워에게 전송한다.
- RDB는 모든 INSERT, UPDATE, DELETE 구문을 팔로워에게 전달하고 각 팔로워는 클라이언트에서 직접 받은 것처럼 SQL 구문을 파싱하고 실행한다.
- statement기반 복제는 매우 간편하지만 복제가 깨질 수 있는 다양한 사례가 있다.
- MySQL은 5.1버전 까지 statement기반 복제를 사용했지만 이후에는 row 기반 복제로 변경했다.



#### 쓰기 전 로그 배송

- 일반적으로 모든 쓰기는 로그에 기록을 한다.
- 이 로그를 기반으로 다른 노드에서 복제 서버를 구성할 수 있다.
- 팔로워가 이 로그를 처리하면 리더에서 있는 것과 정확히 동일한 데이터 구조의 복제본이 만들어진다.
- 이 복제 방식은 postgresql과 오라클 등에서 사용된다.
- 가장 큰 단점은 로그가 제일 저수준 데이터를 기술하기 때문에 복제가 저장소 엔진과 밀접하게 연관된다.

#### 논리적(로우 기반) 로그 복제

- RDB용 논리적 로그는 대개 로우 단위로 데이터베이스 테이블에 쓰기를 기술한 레코드열이다.
- MySQL은 이 방법을 사용한다. (row-based replication)
- 논리적 로그를 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더쉽게 유지할 수 있고 리더와 팔로워에서 다른 버전의 데이터베이스 소프트웨어, 다른 저장소 엔진을 실행할 수 있다.

#### 트리거 기반 복제

- 데이터의 서브셋만 복제하거나 유연하게 동작해야한다면 트리거 기반 복제를 사용할 수 있다.



## 복제 지연 문제

- 읽기요청이 많고 쓰기 요청이 적은 웹 환경에서는 읽기 확장 아키텍처를 사용해서 팔로워를 추가하는 방식으로 처리 용량을 늘릴 수 있다. 이때는 비동기 복제를 사용한다.
- 애플리케이션이 비동기 팔로워에서 데이터를 읽을 때 팔로워가 뒤처진다면 지난 정보를 볼 수도 있다. 하지만 최종일관성은 보장한다.
- 애플리케이션의 지연이 매우 크면 실제 문제가 된다.

### 자신이 쓴 내용 읽기

- 많은 애플리케이션은 사용자가 임의 데이터를 제출하고 해당 사용자에게 제출한 데이터를 다시 볼 수 있게 한다. ex 댓글, 주문내역
- 이 상황에서는 쓰기 후 읽기 일관성(자신의 쓰기 읽기 일관성)이 필요하다. 사용자가 페이지를 재로딩했을 때 항상 자신이 제출한 모든 갱신 정보를 볼 수 있음을 보장하며 다른 사용자에 대해서는 보장하지 않는다.
- 쓰기 후 다음 요청은 반드시 리더를 통해서 읽거나 타임스탬프를 활용하는 방법 등등이 있다.
- 동일한 사용자가 여러 디바이스로 접근할 때는 디바이스 간 쓰기 후 읽기 일관성이 제공되어야 한다.



### 단조 읽기

- 사용자가 시간이 거꾸로 흐르는 현상을 목격할 수 있다.
- 팔로워1에서는 데이터를 읽었는데 팔로워2에서는 데이터를 읽지 못하는 현상
- 단조 읽기는 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하면 된다.

### 일관된 순서로 읽기

- 쓰기의 순서가 달라질때 발생하는 문제가 생길 수 있다.
- 이는 샤딩된 데이터베이스에서 발생하는 특징적인 문제다.
- 해결책은 서로 인과성이 있는 쓰기가 동일한 파티션에 기록되게끔 하는 방법이 있다.

### 복제 지연을 위한 해결책

- 

## 다중 리더 복제

- 리더 기반 복제에서의 단점은 리더가 죽으면 데이터베이스 쓰기가 완전히 불가능해진다는 것이다.
- 다중 리더 설정(master master)은 쓰기를 허용하는 노드를 하나 이상을 두고 각 리더는 동시에 다른 리더의 팔로워 역할도 한다.

### 다중 리더 복제의 사용 사례

- 다중 리더는 이점에 비해 고려해야할 점이 너무 많다

#### 다중 데이터 센터 운영

#### 오프라인 작업을 하는 클라이언트

#### 협업 편집

### 쓰기 충돌 다루기

- 다중 리더 복제에서 제일 큰 문제는 쓰기 충돌이 발생한다는 점이다.

#### 동기 대 비동기 충돌 감지

#### 충돌 회피

#### 일관된 상태 수렴

#### 사용자 정의 충돌 해소 로직

#### 충돌은 무엇인가?

### 다중 리더 복제 토폴로지

- 복제 토폴로지는 쓰기를 한 노드에서 다른 노드로 전달하는 통신 경로를 설명한다.
- 가장 일반적인 토폴로지는 전체 연결(all-to-all) 이다.
- MySQL은 기본적으로 원형 토폴로지만 제공한다.
- 다중 리더 복제 시스템을 활용하려면 쓰기 충돌, 갱신 순서 등등으로 발생할 수 있는 문제를 인지하고 문서를 주의깊게 읽은 다음 데이터베이스를 철저하게 테스트해 실제로 믿을만한 보장을 제공하는지 확인하는게 좋다.

## 리더 없는 복제

- 일부 데이터 저장소 시스템은 리더의 개념을 버리고 모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식을 사용하기도 한다.
- 아마존이 내부 다이나모 시스템에서 사용한 후 리악, 카산드라, 볼드모트 같은 오픈소스 데이터스토어가 등장했다. 이런 스타일을 다이나모 스타일이라고 한다.

### 노드가 다운됐을 때 데이터베이스에 쓰기

- 노드가 세개가있고 한개가 다운되면 두개의 노드에 쓰기만으로도 사용자의 요청은 성공한다. 이후에 다운됐던 노드가 다시 올라왔을때 오래된 데이터 값을 얻을 수 있지만 읽기요청에도 여러 노드에 전송해서 최신값을 얻어내는 방식으로 동작한다.

#### 읽기 복구와 안티 엔트로피

- 사용 불가능한 노드가 온라인 상태가 된 후 누락된 쓰기를 따라잡는 방법

`읽기 복구`

- 클라이언트가 병렬로 읽는 과정에서 오래된 응답을 감지하고 오래된 값을 갖고 있는 해당 서버에 새로운 값을 다시 기록하낟.
- 이 접근 방식은 값을 자주 읽는 상황에 적합하다.

`안티 엔트로피 처리`

- 추가적으로 일부 데이터스토어는 백그라운드 프로세스를 두고 데이터 차이를 지속적으로 찾아 누락된 데이터를 복구한다.
- 리더 기반 복제에서 복제 로그와 달리 이 안티 엔트로피 처리는 특정 순서로 쓰기를 복사하기 때문에 데이터가 복사되기까지 상당한 지연이 있을 수 있다.

#### 읽기와 쓰기를 위한 정족수

- n개의 복제 서버가 있을 때 모든 쓰기는 w개의 노드에서 성공해야 쓰기가 확정되고 모든 읽기는 최소한 r개의 노드에 질의해야 한다.
- w + r > n 이면 읽을 때 최신 값을 얻을 것으로 기대한다.
- 이런 r과 w를 따르는 읽기와 쓰기를 정족수 읽기와 쓰기라고 한다.
- 일반적으로 n은 홀수로하고 w = r = (n + 1) / 2 로 설정한다.
- 다이나모 스타일 데이터베이스는 n, w, r 파라미터는 대개 설정 가능하다.
- 정족수 조건이 w + r > n 이면 다음과 같이 사용 불가능한 노드를 용인한다.
  - w < n 이면 노드 하나를 사용할 수 없어도 여전히 쓰기를 처리할 수 있다.
  - r < n 이면 노드 하나를 사용할 수 없어도 여전히 읽기를 처리할 수 있다.
  - n = 3, w = 2, r = 2이면 사용불가능한 노드 하나를 용인한다.
  - n = 5, w = 3, r = 3이면 사용 불가능한 노드 둘을 용인한다.
  - 일반적으로 읽기와 쓰기는 항상 모든 n개의 복제 서버에 병렬로 전송한다. 파라미터 w와 r은 얼마나 많은 노드를 기다릴지 결정한다. 즉 읽기나 쓰기가 성공했다고 간주하려면 n개의 노드 중 몇 개의 노드에서 성공을 확인해야 하는지 나타낸다.



### 정족수 일관성의 한계

- n개의 복제 서버가 있고 w + r > n이 되게끔 w 와 r을 선택한다면 일반적으로 모든 읽기는 키의 최신 값을 반환할 것을 기대한다.
- w와 r이 작을수록 오래된 값을 읽을 확률이 높다.
- w + r > n 이여도 오래된 값을 반환하는 엣지 케이스가 있다. 결과적으로 무조건 새로운 값을 반환한다는 보장은 없다.



#### 최신성 모니터링

- 운영 관점에서 볼 때 데이터베이스가 최신 결과를 반환하는지 여부를 모니터링하는 일은 중요하다.
- 복제가 명확히 뒤쳐진다면 원인을 조사할 수 있게 알려줘야 한다.
- 리더 기반 복제는 복제지연량을 측정할 수 있지만 리더 없는 복제 시스템에서는 모니터링이 조금 어렵다.

### 느슨한 정족수와 암시된 핸드오프

- 정족수는 내결함성이 없다. 노드가 n개인 대규모 클러스터에서 클라이언트는 네트워크 장애상황일때 일부 데이터베이스노드(특정 값을 위한 정족수 구성에 들어가지 않는 노드 아마 !클러스터 ?)에 연결될 가능성이 있다. 이때 모든 쓰기 요청에 오류를 반환하도록 할 수 있으나 일단 쓰기를 받아들이고 값을 일부 데이터베이스에 저장하는 방법을 느슨한 정족수라고 한다. 비유하자면 내 집 문이 잠겨 들어갈 수 없을때 이웃집 문을 두드려 소파에 잠시 머물 수 있는지 묻는 상황이다.
- 네트워크 장애 상황이 해제되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 해당 노드로 전쏭한다 이 방식을 암시된 핸드오프라고 한다.
- 느슨한 정족수는 쓰기 가용성을 높이는데 유용하다.

### 동시 쓰기 감지

- 다이나모 스타일 데이터베이스는 여러 클라이언트가 동시에 같은 키에 쓰는 것을 허용하기 때문에 엄격한 정족수를 사용하더라도 충돌이 발생한다.



#### 최종 쓰기 승리(동시 쓰기 버리기)

- 복제본이 가진 예전 값을 버리고 가장 최근 값으로 덮어 쓰는 방식
- 쓰기는 자연적인 순서가 없지만 타임스탬프를 붙여서 판단할 수 있다.
- 최종 쓰기 승리라 불리는 충돌 해소 알고리즘은 카산드라에서 유일하게 제공하는 충돌 해소 방법이다.
- 손실 데이터를 허용하지 않는다면 LWW가 충돌 해소에 적합하지는 않다.
- LWW로 데이터를 안전하게 사용하는 유일한 방법은 키를 한번만 쓰고 이후에는 불변값으로 다루는 것이다.
- 카산드라를 사용할때 추천하는 방법은 UUID 키를 사용하는 것이다.

#### "이전 발생" 관계와 동시성

- 한 작업이 다른 작업 이전에 발생했는지가 동시성의 의미를 정의하는 핵심이다. 
- 작업이 다른 작업보다 먼저 발생하지 않으면 단순히 동시 작업이라 말한다.
- 분산시스템에서 동시성을 정의하기 위해 정확한 시간은 중요하지 않다. 두 작업이 발생한 물리적인 시각보다 각 작업이 서로 알지 못하면 단순히 두 작업은 동시에 수행됐다고 말한다.

#### 이전 발생 관계 파악하기

#### 동시에 쓴 값 병합

#### 버전 벡터



## 정리

- 복제는 다양한 용도로 사용할 수 있다.
  - 고가용성: 한 장비가 다운될 때도 시스템이 계속 동작하게 한다.
  - 연결이 끊긴 작업: 네트워크 중단이 있을 때도 애플리케이션이 계속 동작할 수 있게 한다.
  - 지연 시간: 지리적으로 사용자에게 가까이 데이터를 배치해 사용자가 더 빠르게 작업할 수 있게 한다.
  - 확장성: 복제본에서 읽기를 수행해 단일 장비에서 다룰 수 있는 양보다 많은 양의 읽기 작업을 처리할 수 있다.
- 동일한 데이터의 복사본을 여러 장비에 유지하는 간단한 목표임에도 복제는 매우 까다로운 문제다.
- 동시성 그리고 잘못될 수 있는 모든 사항을 주의 깊게 생각하고 그 결함의 결과를 주의 깊게 다뤄야 한다.
- 소프트웨어 버그 때문에 드러나지 않는 데이터 오염과 같이 모르는 사이에 일어나는 결함까지는 고려하지 않더라도 최소한 사용할 수 없는 노드와 네트워크 중단에는 대처해야 한다.
- 복제에 대한 세 가지 주요 접근 방식
  - 단일 리더 복제
    - 클라이언트는 모든 쓰기를 단일 노드로 전송하고 리더는 데이터 변경 이벤트 스트림을 다른 복제 서버로 전송한다. 읽기는 모든 복제 서버가 수행할 수 있지만 팔로워의 읽기는 오래된 값일 수 있다.
  - 다중 리더 복제
    - 클라이언트는 각 쓰기를 여러 리더 노드 중 쓰기를 받아들일 수 있는 노드로 전송한다. 리더는 데이터 변경 이벤트 스트림을 다른 리더와 팔로워 노드로 전송한다.
  - 리더 없는 복제
    - 클라이언트는 각 쓰기를 여러 노드로 전송한다. 클라이언트는 오래된 데이터를 감지하고 이를 바로잡기 위해 병렬로 여러 노드에서 읽는다.
- 각 접근 방식마다 장단점이 있다. 단일 리더 복제는 이해하기 쉽고 충돌 해소에 대한 우려가 없어서 널리 사용된다. 다중 리더 복제나 리더 없는 복제는 결함 노드, 네트워크 중단, 지연 시간 급증이 있는 상황에서 더욱 견고하다. 설명하기 어렵고 일관성이 거의 보장되지 않는다는 점이 다중 리더 복제와 리더 없는 복제의 단점이다.
- 복제는 동기 또는 비동기로 이뤄진다. 동기인지 비동기인지는 결함이 있을 때 시스템 작동에 중요한 영향을 미친다. 비동기 복제는 시스템이 원활히 동작할 때는 빠르지만 복제 지연이 증가하고 서버 장애가 발생하면 어떤 일이 일어났는지 파악하는 작업이 중요하다. 리더가 고장나고 갱신된 팔로워를 비동기로 새로운 리더로 승격하면 최근에 커밋된 데이터를 잃을 수 있다.
- 애플리케이션 복제 지연시 동작해야하는 일부 일관성 모델 세 가지
  - 쓰기 후 읽기 일관성
    - 사용자는 자신이 제출한 데이터를 항상 볼 수 있어야 한다.
  - 단조 읽기
    - 사용자가 어떤 시즘에 데이터를 본 후에는 예전 시스템의 데이터는 나중에 볼 수 없다.
  - 일관된 순서로 읽기
    - 사용자는 인과성이 있는 상태의 데이터를 봐야 한다.
- 다중 리더 복제와 리더 없는 복제는 여러 쓰기가 동시에 발생하는 상황을 허용하기 때문에 충돌이 발생할 수 있다. 







# #6 파티셔닝

- 데이터 셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라 한다.
- 파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 한다.
- 데이터베이스가 여러 파티션을 동시에 건드리는 연산을 지원할 수도 있지만 결과적으로 각 파티션은 그 자체로 작은 데이터베이스가 된다.
- 데이터 파티셔닝을 원하는 주된 이유는 확장성이다. 대용량 데이터셋이 여러 디스크에 분산될 수 있고 질의 부하는 여러 프로세서에 분산될 수 있다.



## 파티셔닝과 복제

- 보통 복제와 파티셔닝을 함께 적용해 각 파티션의 복사본을 여러 노드에 저장한다. (내결함성)
- 한 노드에 여러 파티션을 저장할 수도 있다. 각 노드는 어떤 파티션에게는 리더이면서 다른 파티션에게는 팔로워가 될 수 있다.



## 키-값 데이터 파티셔닝

- 파티셔닝의 목적은 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다.
- 파티션닝이 고르게 이뤄지지 않아 다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있다면 쏠렸다(skewed)고 말한다. 쏠림이 있으면 파티셔닝의 효과가 매우 떨어진다.
- 불균형하게 부하가 높은 파티션을 핫스팟이라고 한다.
- 핫스팟을 회피하는 가장 단순한 방법은 레코드를 할당할 노드를 무작위로 선택하는 것이다. 하지만 어떤 레코드를 읽을때 해당 레코드가 어느 노드에 저장되어 있는지 알 수 없는 큰 단점이 있다.
- 단순한 키-값 모델을 사용한다고 가정했을때 이 모델에서는 항상 기본키를 통해 레코드에 접근한다.

### 키 범위 기준 파티셔닝

- 파티셔닝하는 방법 중 하나는 각 파티션에 연속된 범위의 키를 할당하는 것이다.
- 각 범위들 사이의 경계를 알면 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있다.
- 키의 범위 크기가 반드시 동일할 필요는 없다.
- 파티션 경계는 관리자가 수동으로 선택하거나 데이터베이스에서 자동으로 선택되게 할 수 있다.
- 각 파티션 내에 키를 정렬된 순서로 저장하면 범위 스캔이 쉬워지고 키를 연쇄된 색인으로 간주해서 질의 하나로 관련 레코들 여러 개를 읽어오는 데 사용할 수 있다 ex: 타임스탬프
- 그러나 키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다.



### 키의 해시값 기준 파티셔닝

- 쏠림과 핫스팟의 위험 때문에 많은 분산 데이터스토어는 키의 파티션을 정하는 데 해시 함수를 사용한다.
- 좋은 해시 함수는 쏠린 데이터를 입력으로 받아 균일하게 분산되게 한다. 파티셔닝용 해시 함수는 암호적으로 강력할 필요는 없다.
- 키에 적합한 해시함수를 구했다면 각 파티션 해시값 범위를 할당하고 해시 값이 파티션의 범위에 속하는 모든 키를 파티션에 할당하면 된다.
- 이 기법은 키를 파티션 사이에 균일하게 분산시키는 데 좋지만 단점이 있다. 바로 범위 질의를 효율적으로 실행할 수 있는 능력이다 (키 범위 파티셔닝의 장점)
- 몽고DB는 해시 기반 샤딩 모드를 활성화하면 범위 질의가 모든 파티션에 전송되어야 한다. 카산드라는 복합키를 지정해서 키의 첫 부분에만 해싱을 적용해 파티션 결정에 사용하고 이후엔 데이터 정렬을 위한 연쇄된 색인으로 사용한다 (user_id, update_timestamp)



### 쏠린 작업부하와 핫스팟 완화

- 핫스팟은 완벽히 제거할 수 없다. 항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.
- 이를테면 소셜 미디어 사이트에서 수백만 명의 팔로워를 거느린 유명인이 뭔가를 하면 후폭풍이 발생할 수 있다.
- 현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다. 예를 들면 매우 많이 쏠리는 키에 임의의 수를 붙여 다른 파티션으로 분산시키기
- 하지만 이 경우 읽기를 실행할 때 추가적인 작업이 필요하다. 그 외에도 복잡도가 증가한다.
- 미래에 데이터 시스템은 달라지겠지만 현대는 애플리케이션에 대한 트레이드오프도 꼼꼼히 따져봐야 한다.



##  파티셔닝과 보조 색인

- 레코드를 기본키를 통해서만 접근한다면 키로부터 파티션을 결정하고 이를 사용해 해당 키를 담당하는 파티션으로 읽기 쓰기 요청을 전달할 수 있다.
- 보조 색인이 연관되면 상황은 복잡해진다. 보조색인은 파티션에 깔끔하게 대응되지 않는 문제점이 있다.
- 보조색인이 있는 데이터베이스를 파티셔닝하는 데 널리 쓰이는 두 가지 방법이 있다. 문서 기반 파티셔닝과 용어기반 파티셔닝이다.

### 문서 기준 보조 색인 파티셔닝

### 용어 기준 보조 색인 파티셔닝



## 파티션 재균형화

- 시간이 지나면 데이터베이스에 변화가 생긴다
  - 질의 처리량이 증가해서 늘어난 부하를 처리하기 위해 CPU를 더 추가하고 싶다.
  - 데이터셋 크기가 증가해서 데이터셋 저장에 사용할 디스크와 램을 추가하고 싶다.
  - 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 장비가 넘겨받아야 한다.
- 이런 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다. 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 재균형화라고 한다.
- 어떤 파티셔닝 방식을 쓰는지에 무관하게 재균형화가 실행될 때 보통 만족시킬 것으로 기대되는 최소 요구사항이 있다.
  - 재균형화 후 부하가 클러스터 내 있는 노드들 사이에 균등하게 분배되어야 한다.
  - 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받아들여야 한다.
  - 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져서는 안된다.



### 재균형화 전략

#### 쓰면 안되는 방법: 해시값에 모드 N 연산을 실행

- 모드 연산을 쓰지 않는 이유는 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점이다.



#### 파티션 개수 고정

- 파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 방법이다.
- 클러스터에 노드가 추가되면 새 노드는 파티션이 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 뺏어올 수 있다.
- 이 방식을 사용할 떄는 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않는다.
- 미래에 증가될 것을 수용하기에 충분히 높은 값으로 선택해야 하지만 너무 큰 수를 선택하면 역효과를 낳을 수 있다.



#### 동적 파티셔닝

- 파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 텅 빌 수도 있다. 
- 이런 이유로 Hbase나 리싱크DB처럼 키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션을 동적으로 만든다.
- 동적 파티셔닝은 파티션 개수가 전체 데이터 용량에 맞춰 조정된다는 이점이 있다.
- 빈 데이터베이스에서 파티션 경계를 어디로 정해야하는 지에 관한 사전정보가 없으므로 시작할 때는 파티션이 하나다.
- 이 문제를 완화하기 위해 Hbase와 몽고db에서는 사전 분할로 초기에 파티션 집합을 설정할 수 있게 한다.
- 동적 파티셔닝은 키 범위 파티셔닝, 해시 파티셔닝 모두 사용될 수 있다.
- 몽고 2.4이후부터는 키범위 파티셔닝, 해시 파티셔닝을 사용할 수 있고 모두 파티션을 동적으로 분할하낟.



#### 노드 비례 파티셔닝

- 위에서 설명한 방법 모두 파티션 개수는 노드 대수와 독립적이다.
- 카산드라와 케타마에서 사용되는 세 번째 방법은 파티션 개수가 노드 대수에 비례하게 하는 것이다.
- 노드당 할당되는 파티션 개수를 고정한다.
- 새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다.



### 운영: 자동 재균형화와 수동 재균형화

- 완전 자동 재균형화와 완전 수동 재균형화 사이에는 중간 지점이 있다. 이를테면 카우치베이스, 리악, 볼드모트는 자동으로 파티션 할당을 제안하지만 반영되려면 관리자가 확정해야 한다.
- 완전 자동 재균형화는 일상적인 유지보수에 손이 덜 가므로 편리할 수 있지만 예측하기 어렵다. 재균경화는 비용이 높기 때문에 네트워크나 노드에 과부하가 걸릴 수 있다.
- 문제는 이런 자동화는 자동 장애 감지와 조합되면 위험해질 수 있다.
- 이런 이유로 재균형화 과정에 사람이 개입하는게 좋을 수도 있다.



## 요청 라우팅

- 클라이언트에서 요청을 보내려고 할 때 어느 노드로 접속해야 하는지 어떻게 알 수 있을까?
- 이 문제는 데이터베이스에 국한되지 않은 더 일반적인 문제인 service discovery의 일종이다.
- 상위 수준에서 보면 이 문제는 몇가지 다른 접근법이 있다.
  1. 클라이언트가 아무 노드에나 접속하게 한다. 만약 해당 노드에 마침 요청을 적용할 파티션이 있다면 거기서 요청을 직접 처리하고 아니면 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달한다.
  2. 클라이언트의 몯느 요청을 라우팅 계층으로 먼저 보낸다. 라우팅 계층에서는 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드로 요청을 전달한다. 라우팅은 lb 역할만 한다.
  3. 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다. 이 경우 클라이언트는 중개자 없 이 올바른 노드로 직접 접속할 수 있다.
- 모든 경우에 핵심문제는 라우팅 결정을 내리는 구성요소가 노드에 할당된 파티션의 변경사항을 어떻게 아느냐다.
- 이 문제는 참여하는 모든 곳에서 정보가 일치해야 하므로 다루기 어렵다.
- 많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼 같은 별도의 코디네이션 서비스를 사용한다.

### 병렬 질의 실행

## 정리

- 저장하고 처리할 데이터가 너무 많아서 장비 한 대로 처리하는게 불가능해지면 파티셔닝이 필요하다.
- 파티셔닝의 목적은 핫스팟이 생기지 않게 하면서 데이터와 질의 부하를 여러 장비에 균일하게 분배하는 것이다.
- 그렇게 하려면 데이터에 적합한 파티셔닝 방식을 선택해야 하고 클러스터에 노드가 추가되거나 클러스터에서 노드가 제거될 때 파티션 재균형화를 실행해야 한다.
- 두가지 주요 파티셔닝 기법
  - 키범위 파티셔닝
    - 키가 정렬돼 있고 개별 파티션은 어떤 최솟값과 최댓값 사이의 속하는 모든 키를 담당한다.
    - 키가 정렬되어 있어 범위 질의가 효율적이라는 장점이 있지만 서로 가까운 키에 접근할수록 핫스팟이 생길 위험이 있다.
    - 한 파티션이 너무 커지면 키 범위를 두 개로 쪼개 재균형화를 실행한다.
  - 해시 파티셔닝
    - 각 키에 해시 함수를 적용하고 개별 파티션은 특정 범위의 해시값을 담당한다.
    - 키 순서가 보장되지 않아 질의가 비효율적이지만 더욱 균일하게 분산할 수 있다.
    - 해시 파티셔닝을 사용할 떄는 보통 고정된 개수의 파티션을 미리 만들어 각 노드에 몇 개씩 파티션을 할당하며 노드가 추가되거나 제거되면 파티션을 통째로 노드 사이에서 이동한다.
    - 동적 파티션을 쓸 수도 있다.
  - 두 가지 방법을 섞어 쓸 수도 있다 키의 일부분은 파티션 식별용, 나머지 부분은 정렬 순서용으로 만든 복합키를 사용하는 것이다.
- 파티셔닝과 보조색인 사이의 상호작용
  - 문서 파티셔닝 색인(지역 색인)
    - 보조 색인을 기본키와 값이 저장된 파티션에에 저장한다. 쓸 때는 파티션 하나만 갱신하면 되지만 보조 색인을 읽으려면 모든 파티션에 걸쳐서 스캐터/개더를 실행해야 한다.
  - 용어 파티셔닝 색인(전역 색인)
    - 색인된 값을 사용해서 보조색인을 별도로 파티셔닝한다. 보조 색인 항목은 기본 키의 모든 파티션에 있는 레코드를 포함할 수도 있다. 문서를 쓸 때는 보조 색인 여러 개를 갱신해야 하지만 읽기는 단일 파티션에서 실행될 수 있다.





# #7 트랜잭션

- 냉혹한 현실 세계에서 데이터 시스템은 여러 가지 문제가 생길 수 있다.
  - 데이터베이스 소프트웨어나 하드웨어는 언제라도 실패할 수 있다.
  - 애플리케이션은 언제라도 죽을 수 있다.
  - 네트워크가 끊기면 애플리케이션과 데이터베이스의 연결이 갑자기 끊기거나 데이터베이스 노드 사이의 통신이 안될 수 있다.
  - 여러 클라이언트가 동시에 데이터베이스에 쓰기를 실행해서 다른 클라이언트가 쓴 내용을 덮어쓸 수 있다.
  - 클라이언트가 부분적으로만 갱신돼서 비정상적인 데이터를 읽을 수 있다.
  - 클라이언트 사이의 경쟁 조건은 예측하지 못한 버그를 유발할 수 있다.
- 시스템이 신뢰성을 지니려면 이런 결함을 처리해서 전체 시스템의 치명적인 장애로 이어지는 것을 막아야 한다.
- 수십년동안 트랜잭션은 이런 문제를 단순화하는 메커니즘으로 채택돼 왔다.
- 트랜잭션은 전체가 성공하거나 실패한다.
- 트랜잭션은 데이텁이스의 접속하는 애플리케이션에서 프로그래밍 모델을 단순화하려는 목적으로 만들었다.
- 트랜잭션이 반드시 필요할 수도 있고 아닐 수도 있다. 어떤 안정성 속성은 트랜잭션 없이도 보장될 수 있다.



## 애매모호한 트랜잭션의 개념

- 현대의 모든 관계형 데이터베이스와 일부 비관계형 데이터베이스는 트랜잭션을 지원한다.
- 2000년대 후반에 NoSQL이 등장하면서 트랜잭션을 완전히 포기하거나 훨씬 약한 보장을 제공했고 트랜잭션은 확장성의 안티테제이며 어떤 대규모 시스템이라도 높은 성능과 고가용성을 유지하려면 트랜잭션을 포기해야 한다는 믿음이 널리 퍼졌다.
- 다른 모든 시술적 설계 선택과 마찬가지로 트랜잭션은 이점과 한계가 있다.



### ACID의 의미

- 원자성, 일관성, 격리성 지속성 ACID



**원자성**

- 일반적으로 원자적이란 더 작은 부분으로 쪼갤 수 없는 뭔가를 가리킨다.
- 원자성은 동시성과 관련이 없다. 동시성은 격리성에서 다룬다.
- 원자성은 클라이언트 쓰가 작업을 몇개 실행하려고 하는데 그 중 일부만 처리된 후 결함이 생기면 무슨일이 생기는지를 설명한다.
- 여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료될 수 없다면 실패하고 지금까지 실행한 쓰기를 무시하거나 취소해야 한다.
- 트랜잭션이 실패했다면 애플리케이션에서 이 트랜잭션이 어떤 것도 변경하지 않았음을 알 수 있으므로 안전하게 재시도할 수 있다.

**일관성**

- 일관성이란 단어는 굉장히 여러 의미로 쓰인다.
  - 최종적 일관성
  - 일관성 해싱
  - CAP의 일관성
  - ACID의 맥락에서 일관성은 데이터베이스가 "좋은 상태"에 있어야 한다는 것의 애플리케이션에 특화된 개념을 가리킨다.
- ACID의 일관성의 아이디어는 항상 진실이어야 하는 데이터에 관한 어떤 선언(불변식)이 있다는 것이다
- 그러나 일관성의 아이디어는 애플리케이션 불변식 개념에 의존하고 일관성을 유지하도록 트랜잭션을 올바르게 정의하는 것은 애플리케이션의 책임이다.
- 원자성, 격리성, 지속성은 데이터베이스의 속성인 반면 일관성은 애플리케이션의 속성이다.
- 따라서 C는 실제로 ACID에 속하지 않는다.

**격리성**

- 대부분 동시에 여러 클라이언트에서 데이터베이스에 접속한다.
- 동일한 데이터베이스 레코드에 접근하면 동시성 문제에 맞닥뜨리게 된다.
- ACID에서 격리성은 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미한다.



**지속성**

- 데이터베이스 시스템의 목적은 데이터를 잃어버릴 염려가 없는 안전한 저장소를 제공하는 것이다.
- 지속성은 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장이다.
- 완벽한 지속성은 존재하지 않는다.



### 단일 객체 연산과 다중 객체 연산

- 요약하면 ACID에서 원자성과 격리성은 클라이언트가 한 트랜잭션 내에서 여러번의 쓰기를 하면 데이터베이스가 어떻게 해야 하는지를 서술한다.
- 다중 객체 트랜잭션은 흔히 데이터의 여러 조각이 동기화된 상태로 유지돼야 할 때 필요하다.
- 다중 객체 트랜잭션은 어떤 읽기와 쓰기 연산이 동일한 트랜잭션에 속하는지 알아내는 수단은 TCP 연결을 기반으로 한다.
- 어떤 특정 연결 내에서 BEGIN TRANSACTION 문과 COMMIT 문 사이의 모든 것은 같은 트랜잭션에 속하는 것으로 여겨진다.
- 반면 비관계형 데이터베이스는 이런 식으로 연산을 묶는 방법이 없는 경우가 많다.



**단일 객체 쓰기**

- 원자성과 격리성은 단일 객체를 변경하는 경우에도 적용된다.

**다중 객체 트랜잭션의 필요성**

- 많은 분산 데이터스토어는 다중 객체 트른잭션 지원을 포기했다.
- 단일 객체 삽입, 갱신, 삭제만으로 충분한 사용 사례도 있지만 많은 다른 경우에는 여러 개의 다른 객체에 실행되는 쓰기 작업은 코디네이션 되어야 한다.
- 트랜잭션이 없어도 구현은 가능하지만 원자성이 없으면 오류 처리가 훨씬 복잡해지고 격리성이 없으면 동시성 문제가 생길 수 있다.

**오류와 어보트 처리**

- 트랜잭션의 핵심 기능은 오류가 생기면 어보트되고 안전하게 재시도할 수 있다는 것이다.
- 어보트의 취지는 안전하게 재시도할 수 있도록 하는 것이지만 많은 프로그래머들은 오류처리의 복잡한 내용은 신경쓰지 않고 낙관적인 상황만 생각하려고 한다. 그 이유는 아마 너무 복잡한 문제들 때문에 ..?



## 완화된 격리 수준

- 두 트랜잭션이 동일한 데이터에 접근하지 않으면 서로 의존하지 않으므로 안전하게 병렬 실행될 수 있다.
- 동시성 문제는 트랜잭션이 다른 트랜잭션에서 동시에 변경한 데이터를 읽거나 두 트랜잭션이 동시에 같은 데이터를 변경하려고 할 때만 나타난다.
- 동시성 버그는 타이밍에 운이 없을 때만 촉발되기 때문에 테스트로 발견하기 어렵다.
- 이런 까닭에 데이터베이스는 오랫동안 트랜잭션 격리를 제공함으로써 애플리케이션 개발자들에게 동시성 문제를 감추려 했다.
- 직렬성 격리는 여러 트랜잭션이 직렬적으로 실행되어 동시성문제가 전혀 없지만 이 격리는 성능 비용이 높다.
- 따라서 어떤 동시성 이슈로는 보호해주지만 모든 이슈로부터 보호해주지는 않는 완화된 격리수준을 사용하는 시스템들이 흔하다.
- 맹목적으로 도구에 의존하기보다는 존재하는 동시성 문제의 종류를 잘 이해하고 방지하는 방법을 배울 필요가 있다. 그러면 사용 가능한 도구를 써서 신뢰성 있고 올바르게 동작하는 애플리케이션을 만들 수 있다.

### 커밋 후 읽기

- 가장 기본적인 수준의 트랜잭션 격리는 read committed다. 이 수준에서는 두 가지를 보장해준다.
  - 데이터베이스에서 읽을 떄 커밋된 데이터만 보게 된다. (더티 읽기가 없음)
  - 데이터베이스에 쓸 때 커밋된 데이터만 덮어쓰게 된다. (더티 쓰기가 없음)

**더티 읽기 방지**

- 더다른 트랜잭션에서 커밋되지 않은 데이터를 보는 것을 더티 읽기라 한다.
- 더티 읽기를 막는 이유
  - 트랜잭션이 여러 객체를 갱신하는데 더티 읽기가 생기면 다른 트랜잭션이 일부는 갱신된 값을. 일부는 갱신되지 않은 값을 볼 수 있다.
  - 트랜잭션이 어보트되면 그때까지 쓴 내용은 모두 롤백되어야 한다. 데이터베이스가 더티 읽기를 허용하면 트랜잭션이 나중에 롤백될 데이터. 즉 실제로는 데이터베이스에 결코 커밋되지 않을 데이터를 볼 수 있다.

**더티 쓰기 방지**

- 먼저 쓴 내용이 아직 커밋되지 않은 트랜잭션에서 나중에 실행된 쓰기 작업이 커밋되지 않은 값을 덮어쓰는 것을 더티쓰기라 한다.
- 트랜잭션들이 여러 객체를 갱신하면 더티쓰기는 나쁜 결과를 유발할 수 있다.
- 그러나 커밋 후 읽기는 두 번의 카운터 증가 사이에 발생하는 경쟁 조건은 막지 못한다.



**커밋 후 읽기 구현**

- read committed는 매우 널리 쓰이는 격리 수준이다.
- 가장 흔한 방법으로 데이터베이스는 로우 수준 잠금을 사용해 더티 쓰기를 방지한다.
- 트랜잭션에서 특정 객체를 변경하고 싶다면 먼저 해당 객체에 대한 잠금을 획득해야 하고 트랜잭션이 커밋되거나 어보트될 때까지 잠금을 보유하고 있어야 한다.
- 다른 트랜잭션이 동일한 객체에 쓰기를 원한다면 트랜잭션이 커밋되거나 어보트된 후에야 잠금을 얻어 진행할 수 있다.
- 더티읽기도 같은 방법으로 시도해볼 수 있지만 현실 세계에서는 읽기 트랜잭션이 훨씬 많고 잠금 대기로 인한 지연이 발생할 수 있다.
- 이런 이유로 대부분의 데이터베이스(요즘엔 read committed를 잘 안 씀)는 쓰여진 모든 객체에 대해 과거에 커밋된 값과 현재 쓰기 잠금을 갖고 있는 트랜잭션에서 쓴 새로운 값을 모두 기억한다. 해당 트랜잭션이 실행중인 동안 그 객체를 읽는 다른 트랜잭션들은 과거의 값을 읽게 된다. 새 값이 커밋돼야만 다른 트랜잭션들이 새 값을 읽을 수 있다.



### 스냅숏 격리와 반복 읽기

- read committed은 정말로 유용하며 트랜잭션을 지원하지 않는 시스템에서 얻을 수 있는 것보다 훨씬 더 강력한 보장을 해준다.
- 그러나 이 격리수준을 사용하더라도 동시성 버그가 생길 수 있는 경우가 아직 많이 있다.
- 비반복 읽기와 읽기 스큐(read skew)
- 이런 문제들은 대부분 몇 초 후 다시 조회했을때 일관성을 다시 보장받을 수 있지만 어떤 상황에서는 이런 일시적인 비일관성을 감내할 수 없는 경우도 있다.
- 스냅숏 격리는 이런 문제의 가장 흔한 해결책이다.
- 각 트랜잭션은 데이터베이스의 일관된 스냅숏으로부터 읽는다. 즉 트랜잭션은 시작할 때 데이터베이스에 커밋된 상태였던 모든 데이터를 본다. 데이터가 나중에 트랜잭션에 의해 바뀌더라도 각 트랜잭션은 특정한 시점의 과거 데이터를 볼 뿐이다.
- 스냅숏 격리는 백업이나 분석처럼 실행하는 데 오래 결리며 읽기만 실행하는 질의에 요긴하다.



**스냅숏 격리 구현**

- 스냅숏 격리 구현은 read committed격리 처럼 전형적으로 더티 쓰기를 방지하기 위해 쓰기 잠금을 사용한다.
- 성능 관점에서 스냅숏 격리의 핵심 원리는 읽는 쪽에서 쓰는 쪽을 결코 차단하지 않고 쓰는 쪽에서 읽는 쪽을 결코 차단하지 않는다는 것이다.
- 따라서 데이터베이스는 잠금 경쟁 없이 쓰기 작업이 일상적으로 처리되는 것과 동시에 일관성 있는 스냅숏에 대해 오래 실행되는 읽기 작업을 처리할 수 있다.
- 스냅숏 격리를 구현하기 위해 데이터베이스는 객체마다 커밋된 버전 여러 개를 유지할 수 있어야 한다. 진행중인 여러 트랜잭션에서 서로 다른 시점의 데이터베이스 상태를 봐야 할 수도 있기 때문이다.
- 데이터베이스가 객체의 여러 버전을 함께 유지하므로 이 기법은 다중 버전 동시성 제어 (multi-version concurrency control MVCC) 라고 한다.
- 데이터베이스가 스냅숏 격리가 아니라 커밋 후 읽기 격리만 제공할 필요가 있다면 객체마다 버전 두 개씩만 유지하면 충분하다.
- 전형적인 방법은 read committed는 질의마다 독립된 스냅숏을 사용하고 스냅숏 격리는 전체 트랜잭션에 대해 동일한 스냅숏을 사용하는 것이다.

**일관된 스냅숏을 보는 가시성 규칙**

- 트랜잭션은 데이터베이스에서 객체를 읽을 때 트랜잭션 ID를 사용해 어떤 것을 볼 수 있고 어떤 것을 볼 수 없는지 결정한다.
- 면밀하게 가시성 규칙을 정의함으로써 데이터베이스는 데이터베이스의 일관된 스냅숏을 애플리케이션에게 제공할 수 있다.
  1. 데이터베이스는 각 트랜잭션을 시작할 때 그 시점에 진행 중인 모든 트랜잭션의 목록을 만든다. 이 트랜잭션들이 쓴 데이터는 모두 무시된다. 설령 데이터를 쓴 트랜잭션이 나중에 커밋되더라도 마찬가지다.
  2. 어보트된 트랜잭션이 쓴 데이터는 모두 무시된다.
  3. 트랜잭션 ID가 더 큰 트랜잭션이 쓴 데이터는 그 트랜잭션의 커밋 여부에 관계 없이 모두 무시된다.
  4. 그 밖의 모든 데이터는 애플리케이션 질의로 볼 수 있다
- 아래 두 조건이 참이면 객체를 볼 수 있다.
  - 읽기를 실행하는 트랜잭션이 시작한 시점에 읽기 대상 객체를 생성한 트랜잭션이 이미 커밋된 상태였다.
  - 읽기 대상 객체가 삭제된 것으로 표시되지 않았다. 또는 삭제된 것으로 표시됐지만 읽기를 실행한 트랜잭션이 시작한 시점에 삭제 요청 트랜잭션이 아직 커밋되지 않았다.
- 오래 실행되는 트랜잭션은 오랫동안 스냅숏을 사용해서 덮어써지거나 삭제된지 오래된 값을 계속 읽을 수도 있다. 
- 데이터베이스는 갱신할 때 값을 교체하지 않고 값이 바뀔 때마다 새 버전을 생성함으로써 작은 오버헤드만 유빌하면서 일관된 스냅숏을 제공할 수 있다.

**색인과 스냅숏 격리**

- 현실에선 여러 구현 세부 사항에 따라 MVCC의 동시성 제어 성능이 결정된다.
  - postgresql은 동일한 객체의 다른 버전들이 같은 페이지에 저장될 수 있다면 색인 갱신을 회피하는 최적화를 한다.
  - 카우치 db, 데이토믹, lmdb에서는 추가 전용 B 트리를 사용한다.

**반복된 읽기와 혼란스러운 이름**

- 스냅숏 격리는 유용한 격리 수준이며 특히 읽기 전용 트랜잭션에 유용하다.
- 그러나 이를 구현한 많은 데이터베이스는 다른 이름을 사용한다. 오라클은 직렬성, postgresql은 반복 읽기
- 이렇게 이름이 혼란스러운 이유는 SQL 표준에 스냅숏 격리 개념이 없기 때문이다.



### 갱신 손질 방지

- 동시에 실행되는 쓰기 트랜잭션사이에서 가장 널리 알려진 것은 갱신 손실 문제다.
- 갱신 손실 문제는 애플리케이션이 데이터베이스에서 값을 읽고 변경한 후 변경된 값을 다시 쓸 때 발생할 수 있다.
- 이런 패턴은 다양한 시나리오에서 발생한다
  - 카운터를 증가시키거나 계좌 잔고를 갱신할 때
  - 복잡한 값을 지역적으로 변경할 때
  - 위키에서 두 명의 사용자가 동시에 같은 페이지를 편집할 때
- 갱신 손실은 이렇게 흔한 문제라서 다양한 해결책이 개발됐다.



**원자적 쓰기 연산**

- 여러 데이터베이스에서 원자적 갱신 연산을 제공한다.

```sql
UPDATE conters SET value = value + 1 WHERE key = 'foo';
```

- 이런 연산을 써서 코드를 표현할 수 있다면 이것이들이 보통 가장 좋은 해결 책이다.
- 원자적 연산은 보통 객체를 읽을 때 그 객체에 exclusive lock을 획득해서 구현한다.
- 그래서 갱신이 적용될 때까지 다른 트랜잭션에서 그 객체를 읽지 못하게 한다. 이 기법을 커서 안정성 이라고 부르기도 한다.



**명시적인 잠금**

- 데이터베이스에 내장된 원자적 연산이 필요한 기능을 제공하지 않을 때 갱신 손실을 막는 또다른 선택지는 애플리케이션에서 갱신할 객체를 명시적으로 잠그는 것이다.

```sql
BEGIN TRANSACTION;

SELECT * FROM figures
WHERE name = 'robot' AND game_id = 222

-- 이동이 유효한지 확인한 후
-- 이전의 SELECT에서 반환된 것의 위치를 갱신한다.
UPDATE figures SET position = 'c4' WHERE id = 1234;

COMMIT;
```

- FOR UPDATE 절은 데이터베이스가 이 질의에 의해 반환된 모든 로우에 잠금을 획득해야 함을 가리킨다.
- 이 방법은 동작하지만 코드의 어딘가에 필요한 잠금을 추가하는 것을 잊어버려서 경쟁 조건을 유발하기 쉽다.



**갱신 손실 자동 감지**

- 원자적 연산과 잠금은 read-modify-write 주기가 순차적으로 실행되도록 강제함으로써 갱신 손실을 방지하는 방법이다.
- 대안으로 이들의 병렬 실행을 허용하고 트랜잭션 관리자가 갱신 손실을 발견하면 트랜잭션을 어보트시키고 read-modify-write 주기를 재시도하도록 강제하는 방법이 있다.
- 이 방법의 이점은 데이터베이스가 이 확인을 스냅숏 격리와 결합해 효율적으로 수행할 수 있다는 것이다.
- 갱신 손실 감지는 애플리케이션 코드에서 어떤 특별한 데이터베이스 기능도 쓸 필요가 없게 도와주므로 매우 좋은 기능이다.
  - 오라클, postgresql



**Compare-and-set**

- 트랜잭션을 제공하지 않는 데이터베이스 중에는 원자적 compare-and-set연산을 제공하는 것도 있다.
- 이 연산의 목적은 값을 마지막으로 읽은 후로 변경되지 않았을 때만 갱신을 허용함으로써 갱신 손실을 회피하는 것이다.



**충돌 해소와 복제**

- 복제가 적용된 데이터베이스에서 갱신 손실을 막는 것은 어렵다. 여러 노드에 데이터의 복사본이 있어서 다른 노드들에서 동시에 데이터가 변경될 수 있으므로 갱신 손실 방지하려면 추가 단계가 필요하다.
- 여러 개의 충돌된 버전을 생성하는 것을 허용하고 사후에 애플리케이션 코드나 특별한 데이터 구조를 사용해 충돌을 해소하고 이 버전들을 병합하는 것이다.
- 반면 최종 쓰기 승리 충돌 해소 방법은 갱신 손실이 발생하기 쉽다. 많은 복제 데이터베이스는 최종 쓰기 승리가 기본 설정이다.



### 쓰기 스큐와 팬텀

**쓰기 스큐를 특정짓기**

- 두 트랜잭션이 두 개의 다른 객체를 갱신하므로 더티쓰기도 갱신 손실도 아닌 쓰기 스큐라고 한다.
- 쓰기 스큐를 자동으로 방지하려면 직렬성 격리가 필요하다.
- 직렬성 격리 수준을 사용할 수 없다면 트랜잭션이 의존하는 로우를 명시적으로 잠그는 것이 차선책이다.



**추가적인 쓰기 스큐의 예**

- 쓰기 스큐는 매우 많은 상황에서 발생할 수 있다.

**쓰기 스큐를 유발하는 팬텀**

1. SELECT했는데 결과가 없음
2. 결과가 없는것으로 판단하고 쓰기처리
3. 다시 1번을 조회했는데 다른 결과를 얻게 됨



- SELECT 시점에는 exclusive lock이 불가능하다.
- 어떤 트랜잭션에서 실행한 쓰기가 다른 트랜잭션의 검색 질의 결과를 바꾸는 효과를 팬텀이라고 한다.
- 스냅숏 격리는 읽기 전용 질의에서는 회피하지만 쓰기 트랜잭션에서는 팬텀이 쓰기 스큐의 까다로운 경우를 유발할 수 있다.



**충돌 구체화**

- 미리 예상되는 잠금들에 대한 로우드를 미리 만들어두고 예약을 원하는 트랜잭션은 해당 로우를 잠그는 방식으로 해결할 수 있다.
- 이런 방법을 충돌 구체화라고 한다.
- 팬텀을 데이터베이스에 존재하는 구체적인 로우 집합에 대한 잠금 충돌로 변환하기 때문이다.
- 유감스럽게도 충돌을 구체화하는 방법은 알아내기 어렵고 오류가 발생하기 쉽기 때문에 충돌 구체화는 대안이 없을때 하는 최후의 수단으로 고려해야 한다
- 대부분의 경우 직렬성 격리 수준이 훨씬 더 선호된다.



## 직렬성

1. 격리수준은 이해하기 어렵고 데이터베이스마다 그 구현에 일관성이 없다.
2. 애플리케이션 코드를 보고 특정한 격리 수준에서 해당 코드를 실행하는게 안전한지 알기 어렵다.
3. 동시성 문제는 보통 비결정적이라서 테스트하기 어렵다.

- 연구자들의 대답도 쭉 간단하다. 직렬성 격리를 사용하라
- 직렬성 격리수준은 모든 경쟁 조건을 막아준다.



### 실제적인 직렬 실행

- 동시성 문제를 피하는 가장 간단한 방법은 동시성을 완전히 제거하는 것이다.
- 단일 스레드 실행이 가능하게 된 이유
  - 하드웨어의 가격이 저렴해져서 데이터셋 전체를 램 메모리에 유지할 수 있을 정도가 됐다.
  - OLTP는 트랜잭션이 보통 짧고 쓰기의 개수가 적다는 것을 깨달았다.
- 트랜잭션을 순차적으로 실행하는 방법은 레디스, 데이토믹에서 구현됐다.
- 이들의 처리량은 CPU 코어 하나의 처리량으로 제한된다.



**트랜잭션을 스토어드 프로시저 안에 캡슐화하기**

- 트랜잭션은 계쏙 상호작용하는 클라이언트/서버 스타일로 실행돼 왔다. 한 번에 구문 하나씩 실행하는 방식이다.
- 이런 상호작용식 트랜잭션은 애플리케이션과 데이터베이스 사이의 네트워크 통신에 많은 시간을 소비한다.
- 이런 종류의 데이터베이스에서 쓸 만한 성능을 얻으려면 여러 트랜잭션을 동시에 실행할 필요가 있다.



**스토어드 프로시저의 장단점**

- 스토어드 프로시저는 단점이 많다. 하지만 현대의 프로시저 구현은 PL/SQL을 버리고 범용 프로그래밍 언어를 사용한다.
- 스토어드 프로시저가 있고 데이터가 메모리에 저장된다면 모든 트랜잭션을 단일 스레드에서 실행하는 게 현실성이 있다.
- I/O 대기가 필요 없고 다른 동시성 제어 메커니즘의 오버헤드를 회피하므로 단일 스레드로 상당히 좋은 처리량을 얻을 수 있다.



**파티셔닝**

- 모든 트랜잭션을 순차적으로 실행하면 동시성 제어는 훨씬 간단해지지만 데이터베이스의 트랜잭션 처리량이 단일 장비에 있는 단일 CPU 코어의 속도로 제한된다.
- 쓰기 처리량이 높은 애플리케이션에게 단일 스레드 트랜잭션 처리자가 심각한 병목이 될 수 있다.
- 여러 CPU와 여러 노드로 확장하기 위해 데이터를 파티셔닝 할 수도 있다.
- 이 경우 CPU 코어에 각자 파티션을 할당해서 트랜잭션 처리량을 CPU 코어 개수에 맞춰 선형적으로 확장할 수 있다.
- 그러나 여러 파티션에 접근해야 하는 트랜잭션이라면 데이터베이스가 해당 트랜잭션이 접근하는 모든 파티션에 거쳐서 코디네이션을 해야 한다.



**직렬 실행 요약**

- 트랜잭션 직렬 실행은 몇 가지 제약 사항 안에서 직렬성 격리를 획득하는 실용적인 방법이 됐다.
  - 모든 트랜잭션은 작고 빨라야 한다.
  - 활성화된 데이터셋이 메모리에 적재될 수 있는 경우로 사용이 제한된다.
  - 쓰기 처리량이 단일 CPU 코어에서 처리할 수 있을 정도로 충분히 낮아야 한다.
  - 여러 파티션에 걸친 트랜잭션도 쓸 수 있지만 이것을 사용할 수 있는 정도에는 엄격한 제한이 있다.



### 2단계 잠금 (2PL)

- 2PL은 MySQL과 SQL 서버에서 직렬성 격리 수준을 구현하는 데 사용되고 DB2에서는 반복 읽기 격리 수준을 구현하는 데 사용된다.
- 읽는 쪽과 쓰는 쪽을 막는 것은 데이터베이스의 각 객체에 잠금을 사용해 구현한다.
- 잠금은 share mode, exclusive mode로 사용될 수 있다.
  - 트랜잭션이 객체를 읽기 원한다면 먼저 공유 모드로 잠금을 획득해야 한다. 동시에 여러 트랜잭션이 공유 모드로 잠금을 획득하는 것은 허용되지만 만약 그 객체에 이미 독점 모드로 잠금을 획득한 트랜잭션이 있으면 이 트랜잭션이 완료될 때까지 기다려야한다.
  - 트랜잭션이 객체에 쓰기를 원한다면 먼저 독점 모드로 잠금을 획드해야 한다. 다른 어떤 트랜잭션도 동시에 잠금을 획득할 수 없으므로 그 객체에 잠금이 존재한다면 트랜잭션은 대기해야 한다.
  - 트랜잭션이 객체를 읽다가 쓰기를 실행할 때는 공유 잠금을 독점 잠금으로 업그레이드해야 한다. 업그레이드는 독점 잠금을 직접 획득할 때와 똑같이 동작한다.
  - 트랜잭션이 잠금을 획득한 후에는 트랜잭션이 종료될 때까지 잠금을 갖고 있어야한다 그래서 2단계 라는 이름이 붙었다. 첫번째 단계는 잠금을 획득할때, 두번째단계는 모든 잠금을 해제할 때
- 이경우 A는 B를대기 B는 A를 대기하는 교착상태가  발생할 수 있다.
- 데이터베이스는 트랜잭션 사이의 교착 상태를 자동으로 감지하고 트랜잭션 중 하나를 어보트 시켜서 다른 트랜잭션들이 진행할 수 있게 한다.



**2단계 잠금의 성능**

- 2단계 잠금의 큰 약점은 성능이다.
- 트랜잭션에는 실행시간을 제한하지 않는다.
- 2PL을 실행하는 데이터베이스는 작업부하에 경쟁이 있다면 지연 시간이 아주 불안정하고 높은 백분위에서 매우 느릴 수 있다.
- 교착상태도 많이 발생한다.



**서술 잠금**

**색인 범위 잠금**

- 유감스럽게도 서술 잠금은 잘 동작하지 않는다.
- 2PL을 지원하는 대부분의 데이터베이스는 실제로 색인 범위 잠금(index-range locking) 또는 next key locking 이라한다.
- 어떤 방법을 쓰든지 간략화한 검색 조건이 색인 중 하나에 붙는데 이제 다른 트랜잭션이 같은 인덱스를 사용한다면 이부분을 삽입, 갱신, 삭제하길 원한다면 같은 부분을 갱신해야 한다. 그 과정에서 공유 잠금을 발견하고 잠금이 해제될 때까지 기다리게 된다.
- 이 방법을 쓰면 쓰기 스큐로부터 보호해주는 효과를 낳는다. 오버헤드가 낮기 때문에 좋은 타협안이 된다.
- 범위 잠금을 잡을 수 없는 적합한 색인이 없다면 데이터베이스는 테이블 전체에 공유 잠금을 잡는 것으로 대체할 수 있다.



### 직렬성 스냅숏 격리

- 직렬성 격리와 좋은 성능은 근본적으로 공존할 수 없는 것일까?
- 직렬성 스냅숏 격리라는 알고리즘이 아주 유망하다.



**비관적 동시성 제어 대 낙관적 동시성 제어**

- 2단계 잠금은 이른바 비관적 동시성 제어 메커니즘이다. 뭔가 잘못될 가능성이 있으면 뭔가를 하기 전에 상황이 다시 안전해질 때까지 기다리는게 낫다는 원칙을 기반으로 한다.
- 반대로 직렬성 스냅숏 격리는 낙관적 동시성 제어 기법이다. 이 맥락에서 낙관적이란 뭔가 위험한 상황이 발생할 가능성이 있을 때 트랜잭션을 막는 대신 모든 것이 괜찮아질 거라는 희망을 갖고 계속 진행한다는 뜻이다.
- 트랜잭션이 커밋되기전에 데이터베이스에 나쁜 상황이 발생했는지 확인하고 만약 그렇다면 트랜잭션은 어보트된다.
- 낙관적 동시성 제어는 경쟁이 심하면 어보트시켜야 할 트랜잭션의 비율이 높아진다.
- 예비 용량이 충분하고 트랜잭션 사이의 경쟁이 너무 심하지 않으면 비관적 동시성 제어보다 성능이 좋다.
- 이름에서 나타내듯이 SSI는 스냅숏 격리를 기반으로 한다. 즉 트랜잭션에서 실행되는 모든 읽기는 데이터베이스의 일관된 스냅숏을 보게 된다.



**뒤처진 전제에 기반한 결정**

- 스냅숏 격리에서는 트랜잭션이 커밋되는 시점에 원래 질의 결과가 더 이상 최신이 아닐 수 있다.
- 애플리케이션이 질의를 실행할 때 데이터베이스는 애플리케이션 로직이 질의 결과를 어떻게 사용할지 모른다.
- 데이터베이스가 어떻게 질의 결과가 바뀌었는지 알 수 있을까?
  - 오래된 MVCC 객체 버전을 읽었는지 감지하기
  - 과거의 읽기에 영향을 미치는 쓰기 감지하기



**오래된 MVCC 읽기 감시하기**

- MVCC 가시성 규칙에 따라 다른 트랜잭션의 쓰기를 무시하는 경우를 추적해야 한다.
- 트랜잭션이 커밋하려고 할 때 데이터베이스는 무시된 쓰기 중에 커밋된게 있는지 확인하고 커밋된 게 있다면 트랜잭션은 어보트되어야 한다.
- 트랜잭션이 읽기를 실행하는 시점에 데이터베이스는 이 트랜잭션이 나중에 쓰기를 실행할지 알 수 없기 때문에 커밋할 때까지 기다린다.
- SSI는 불필요한 어보트를 피해서 이관된 스냅숏에서 읽으며 오래 실행되는 작업을 지원하는 스냅숏 격리의 특성을 유지한다.



**과거의 읽기에 영향을 미치는 쓰기 감지하기**



**직렬성 스냅숏 격리의 성능**

- 늘 그렇듯이 여러 공학적 세부 사항은 현실에서 알고리즘이 얼마나 잘 동작하는지에 영향을 미친다. 예를 들어 한 가지 트레이드오프는 트랜잭션의 읽기 쓰기를 추적하는 세밀함 정도다.
- 2단계 잠금과 비교할 때 직렬성 스냅숏 격리의 큰 이점은 트랜잭션이 다른 트랜잭션들이 잡고 있는 잠금을 기다리느라 차단될 필요가 없다는 것이다.
- 스냅숏 격리하에서와 마찬가지로 쓰는 쪽은 읽는 쪽을 막지 않고 읽는 쪽도 쓰는 쪽을 막지 않는다.
- 읽기 전용 질의는 어떤 잠금도 없이 일관된 스냅숏 위에서 실행될 수 있어서 읽기 작업 부하가 심한 경우에 매우 매력적이다
- 순차 실행과 비교할 때 직렬성 스냅숏 격리는 단일 CPU 코어의 처리량에 제한되지 안흔ㄴ다.
- 어보트 비율은 SSI의 전체적인 성능에 큰 영향을 미친다. SSI는 쓰기 트랜잭션이 상당히 짧기를 요구한다.





## 정리

- 트랜잭션은 애플리케이션이 어떤 동시성 문제와 어떤 종류의 하드웨어와 소프트웨어 결함이 존재하지 않는 것처럼 동작할 수 있게 도와주는 추상층이다.

- 많은 종류의 오류가 간단한 트랜잭션 어보트로 줄어들고 애플리케이션은 재시도만 하면 된다.

- 접근 패턴이 복잡할 때는 트랜잭션이 상상할 수 있는 잠재적인 오류 상황의 수를 크게 줄여줄 수 있다.

- 트랜잭션이 없다면 데이터 일관성을 유지하기 어렵고 복잡한 상호작용을 하는 접근이 데이터베이스에 미치는 영향을 따져보기가 매우 어려워진다.

- 용어 정리

  - 더티 읽기
    - 한 클라이언트가 다른 클라이언트가 썼지만 아직 커밋되지 않은 데이터를 읽는다. 커밋 후 읽기 또는 그보다 강한 격리수준은 더티 읽기를 방지한다.
  - 더티 쓰기
    - 한 클라이언트가 다른 클라이언트가 썼지만 아직 커밋되지 않은 데이터를 덮어쓴다. 거의 모든 트랜잭션 구현은 더티 쓰기를 방지한다.
  - 읽기 스큐(비반복 읽기)
    - 클라이언트는 다른 시점에 데이터베이스의 다른 부분을 본다. 이 문제를 막기 위한 해결책으로 트랜잭션이 어느 시점의 일관된 스냅숏으로부터 읽는 스탭숏 격리를 가장 흔히 사용한다. 스냅숏 격리는 보통 MVCC를 써서 구현한다.
  - 갱신 손실
    - 두 클라이언트가 동시에 read-modify-write 주기를 실행한다. 한 트랜잭션이 다른 트랜잭션의 변경을 포함하지 않은 채로 다른 트랜잭션이 쓴 내용을 덮어써서 데이터가 손실된다. 스냅숏 격리 구현 중 어떤 것은 이런 현상을 자동으로 막아주지만 그렇지 않는 것은 수동 잠금이 필요하다.
  - 쓰기 스큐
    - 트랜잭션이 무언가를 읽고 읽은 값을 기반으로 어떤 결정을 하고 데이터베이스에 쓴다. 그러나 쓰기를 실행하는 시점에는 결정의 전제가 더 이상 참이 아니다. 직렬성 격리만 이런 현상을 막을 수 있다.
  - 팬텀 읽기
    - 트랜잭션이 어떤 검색 조건에 부합하는 객체를 읽는다. 다른 클라이언트가 그 검색 결과에 영향을 주는 쓰기를 실행한다. 스냅숏 격리는 간단한 팬텀 읽기는 막아주지만 쓰기 스큐 맥락에서 발생한 팬텀은 색인 범위 잠금처럼 특별한 처리가 필요하다.

  

  

  

  













