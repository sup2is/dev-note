http://www.hanbit.co.kr/src/10280





# #1 아파치 카프카 개요

## 아파치 카프카

- 아파치 카프카는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메시징 시스템
- 메시지를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용
- 카프카의 실현 4가지
  1. **확장성:** 여러 서버로 확장 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장 가능
  2. **영속성:** 수신한 데이터를 '디스크에 유지'할 수 있기 때문에 언제라도 데이터를 읽을 수 있음
  3. **유연성:** '연계할 수 있는 제품이 많기' 때문에 제품이나 시스템을 연결하는 허브 역할을함
  4. **신뢰성:** ''메시지 전달 보증''을 하므로 데이터 분시을 걱정하지 않아도 됨

- 카프카 자체가 높은 처리량으로 데이터를 실시간 처리하는 처리 성능에 초점을 두었음

## 카프카 탄생 배경

### 링크드인의 시스템 요구사항

- 카프카는 2011년 링크드인에서 출발, 웹사이트에서 생성되는 로그를 처리하여 웹사이트 활동을 추적하는 것을 목적으로 개발
- 링크드인의 실현 목표
  1. **높은 처리량으로 실시간 처리**
     - 전 세계 사용자의 방대한 엑세스 데이터를 처리하기 위해 우수한 처리량 필수
  2. **임의의 타임이에 데이터를 읽기**
     - 실시간처리 뿐만아니라 기존에 있는 데이터를 처리할 버퍼 역할 포함
  3. **다양한 제품과 시스템에 쉽게 연동**
     - 이용 목적에 따라 DB, 데이터웨어하우스, 하둡 등의 다른 제품과의 쉬운 연결
  4. **메시지를 잃지 않음**
     - 취급하는 메시지가 방대하더라도 메시지를 잃어서는 안됨.

### 카프카 이전 제품

#### 메시지큐

- IBM WebSphere MQ, RabbitMQ, ActiveMQ 등이 있음
- 링크드인에서 요구하는 사항과 일치하지 않는 사항들
  - **강력한 전달 보증이 오버스펙:** IBM WebSphere MQ는 메시지 단위로 트랜잭션을 지원하는 기능이 있음 이런 기능은 하나의 메시지가 정확하게 한번만 전송되는 것을 보장할 수 있지만 링크드인에서 다루는 로그의 성질을 고려하면 오버스펙이였음. 높은 처리량이 우선이여서 배제
  - **스케일 아웃이 용이한 제품이 아님:** 대량의 메시지를 처리하는데 1대의 서버로만 대응하는 것은 한계가 있음 기존 제품들도 클러스터 구성이 가능한것이 있었지만 실제로는 가용성을 위한 중복 구성에 주안점을 두고 있었음. 단순히 처리량을 높이는 목적으로 스케일 아웃 기능을 한 제품은 없었음
  - **메시지가 대량으로 쌓이는 것을 예상하지 않음:** 기존의 메시지 큐는 즉시 이용되는것을 예상했지만 장시간 대량을 축척하는 것을 예상하지 않았음 링크드인에서는 실시간뿐만아니라 대량의 배치처리도 가정하고 있었으므로 시존 메시지 큐로 감당 불가능

#### 로그 수집 시스템

- 페이스북의 Scribe, 클라우데라의 Flume
- 각 프론트엔드 서버가 중계용 서버에 로그를 전달하고 거기서 로그를 수집하여 데이터베이스와 분산파일 시스템 HDFS(Hadoop Distributed File System)에 축적함
- 링크드인에서 요구하는 사항과 일치하지 않는 사항들
  - **HDFS로 데이터 축적과 배치 처리만 고려함**: 링크드인에서도 하둡을 사용했지만 데이터 웨어하우스를 이용한 데이터 분석도 실시하고 있어서 배제, 또한 데이터를 배치 뿐만아니라 실시간으로 처리하고자 하는 요구가 있었음
  - **알기 쉬운 API가 없음:** 카프카 이전의 제품은 미들웨어 내의 구현 사양을 모르면 사용하기 힘들다는 지적이 있었음 데이터 송신 수신에 있어서 이용하기 쉬운 API가 필요했음
  - **수신하는 쪽이 임의로 메시지를 수신하기 어려움:** 기존제품들은 송신시스템에 push에 의존했지만 수신시스템이 pull 하는 방식이 오히려 더 사용하기 쉽다고 생각함

## 카프카로 링크드인 요구 사항 실현하기

- 요구사항
  1. 높은 처리량으로 실시간 처리를 한다
  2. 임의의 타이밍에 데이터를 읽는다
  3. 다양한 제품과 시스템에 쉽게 연동한다
  4. 메시지를 잃지 않는다.
- 실현 수단
  1. 메시징 모델과 스케일 아웃형 아키텍처
  2. 디스크로의 데이터 영속화
  3. 이해하기 쉬운 api 제공
  4. 전달 보증

### 메시징 모델과 스케일 아웃

- 여기에 해당하는 요구사항
  1. 높은 처리량으로 실시간 처리를 한다
  2. 임의의 타이밍에 데이터를 읽는다
  3. 다양한 제품과 시스템에 쉽게 연동한다

- 이러한 요구사항을 해걸하기 위해 카프카는 메시징 모델을 채용함
- 일반적으로 메시징 모델은 다음 세가지 요소로 구성됨
  1. **Producer:** 메시지 생산자
  2. **Broker:** 메시지 수집/전달 역할
  3. **Consumer:** 메시지 소비자

- Producer -> Broker -> Consumer

#### 큐잉 모델

- 브로커 안에 큐를 준비해 프로듀서의 메시지가 큐에 담기고 컨슈머가 큐에서 메시지를 추출함
- 하나의 큐에 대해 컨슈머가 여러개 존재하는 것을 생각할 수 있음
- 메시지는 하나의 컨슈머에게만 보장함
- 큐에서 여러개의 컨슈머가 메시지를 추출할 수 있어 컨슈머에 의한 병렬 처리 가능
- 하나의 메시지는 여러 컨슈머 중 어느 하나에서 처리함

#### 펍/섭 메시징 모델

- 이 모델에서는 프로듀서를 퍼블리셔, 컨슈머를 서브스크라이버 라고함
- 역시 브로커의 개념이 있음
- 퍼블리셔는 누가 그 메시지를 수신하는지 알 수 없고 브로커에 있는 토픽이라고 불리는 카테고리 안에 메시지를 등록함
- 퍼블리셔는 브로커에게 메시지를 보내기만하고 그 메시지를 이용하는건 신경쓰지 않음
- 퍼블리셔의 메세지는 브로커 내의 토픽이라 불리는 부분에 등록함
- 서브스크라이버는 여러개 존재하는 토픽 중 하나를 선택하여 메시지를 받음 여러 서비스크라이버가 동일한 토픽을 구독하기로 결정했다면 이 여러 서브스크라이버는 동일한 메시지를 받게됨 큐잉모델과 다른점

#### 프로듀서/컨슈머 사이에 브로커를 끼우는 장점

- **프로듀서/컨슈머 모두 접속처를 하나로 할 수 있다:** 프로듀서는 메시지를 단순히 브로커로만 보내면되고 컨슈머는 브로커에서 수신만 하면됨.
- **프로듀서/컨슈머 증감에 대응할 수 있음:** 서로의 존재를 모르기때문에 증감에 유연하게 동작 가능

#### 큐잉모델과 펍/섭 메시징 모델

- 큐잉모델과 펍/섭 메시징모델의 가장 큰 차이는 메시지를 소비하는 형식인데 펍/섭 모델의 경우 전부 다 같은 메시지를 소비하기 때문에 병렬로 동작하는 복수의 서브스크라이버에게 메시지를 전달하는 장점이 있지만 처리 능력을 높이는 효과는 없음

### 카프카 메시징 모델

- 카프카는 큐잉모델과 펍/섭모델로 구성되어 있고 이 모델을 실현하기 위해 컨슈머 그룹 이라는 개념을 도입해서 컨슈머를 확장 구성할 수 있도록 설계했음
- 브로커가 1대라면 병목이 될 수 있기때문에 브로커 역시 복수 구성이 가능함

### 디스크로의 데이터 영속화

- 여기에 해당하는 요구사항
  1. 임의의 타이밍에 데이터를 읽는다
  2. 메시지를 잃지 않는다.

- 카프카의 영속화는 디스크에서 이루어짐. 카프카는 **디스크에 영속화함에도 불구하고 높은 처리량을 제공**한다는 특징이 있음
- 카프카는 들어오는 데이터를 받아 한 묶음으로 장기간 영속화 시킬 수 있어서 **스토리지 시스템**으로도 간주할 수 있음



### 이해하기 쉬운 API 제공

- 여기에 해당하는 요구사항
  1. 다양한 제품과 시스템에 쉽게 연동
- 카프카는 프로듀서와 컨슈머를 쉽게 접속할 수 있도록 **Connect API**를 제공함 이 api를 이용하여 각종 외부 시스템과 접속하고 API를 기반으로 카프카에 접속하기 위한 프레임워크로 Kafka Connect도 제공함
- 데이터베이스, 키 밸류 스토어, 검색인덱스 등의 다양한 커넥터가 존재함
- Kafka streams로 입출력에 사용하는 스트림 처리 에플리케이션을 쉽게 구축 가능함

### 전달 보증

- 여기에 해당하는 요구사항
  1. 메시지를 잃지 않음
- 카프카의 전달 보증 수준

| 종류          | 개요                    | 재전송 유무 | 중복 삭제 유무 | 비고                                                         |
| ------------- | ----------------------- | ----------- | -------------- | ------------------------------------------------------------ |
| At Most Once  | 1회는 전달을 시도해본다 | X           | X              | 메시지는 중복되지 않지만 상실될 수 있다                      |
| At Least Once | 적어도 1회는 전달한다   | O           | X              | 메시지가 중복될 가능성은 있지만 상실되지 않는다.             |
| Exactly Once  | 1회만 전달한다.         | O           | O              | 중복되거나 상실되지도 않고 확실하게 메시지가 도달하지만 성능이 나오기가 힘들다. |

- 기존 MQ는 Exactly Once 수준을 주 목적으로 하는 경우가 많았음
- **At Least Once:** At Least Once를 실현하기 위해 Ack와 오프셋 커밋이라는 개념을 도입함 Ack는 브로커가 메시지를 수신했을 때 프로듀서에게 수신 완료 했다는 응답을 뜻함 이것으로 메시지 상실을 판단, 컨슈머가 어디까지 메세지를 받았는지 관리하기 위한 오프셋이 있고 이 전달 범위 보증의 구조를 오프셋 커밋이라고함. 이 오프셋 커밋을 통해서 메시지 재전송시에 어디서부터 재전송하면 되는지 판단 가능
- **Exactly Once:** 구체적으로 쌍방간의 실현이 모두 필요함 프로듀서와 브로커의 상호교환 사이, 컨슈머와 브로커의 상호 교환 사이 자세한 설명은 그림 



## 카프카의 확산

- 2011년 0.7 버전 출시 이후 2018년 7월 2.0 출시, 지속적인 활발한 오픈소스
- 링크드인, 야후, 넷플릭스, 시스코, 골드만삭스, 트위터, 우버, 마이크로소프트 등 굉장히 많은 기업에서 이미 카프카를 사용하고 있음



# #2 카프카 기초

## 메시지 송수신의 기본

카프카의 주요 구성 요소

- **브로커:** 데이터를 수신 전달하는 서비스
- **메시지:** 카프카에서 다루는 데이터의 최소 단위, 키밸류 형식
- **프로듀서:** 데이터의 생산자이며 브로커에게 메시지를 보내는 애플리케이션
- **컨슈머:** 브로커에서 메시지를 취득하는 애플리케이션
- **토픽:** 메시지의 종류 별로 관리하는 스토리지, 브로커에 배치되어 관리.  단일 카프카 클러스터에서 여러 종류의 메시지를 중개함



## 시스템 구성

**브로커**

-  하나의 서버 또는 인스턴스당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들임
- 여러대의 클러스터로 구성할 수 있으며 브로커를 추가함으로써 수신/전달의 처리량 향상 스케일 아웃이 가능
- 브로커에서 받은 데이터는 전부 영속화가 이루어져 장기간 데이터 보존 가능

**프로듀서 API/ 컨슈머 API**

- 프로듀서 컨슈머를 구현하는 기능은 라이브러리로 제공됨 그것들을 각각 프로듀서 API, 컨슈머 API라고 칭하고 각각 API는 자바로 제공됨

**프로듀서**

- 프로듀서는 프로듀서 API를 이용하여 브로커에 데이터를 송신하기 위해 구현된 애플리케이션
- 프로듀서 기능을 내장하거나 서드 파티 플러그인 제휴를 통해 제공하는 다양한 오픈소스 소프트웨어가 있음 (Apache Log4j, Logstash ...)

**컨슈머**

- 컨슈머 API를 이용하여 메시지를 취득하도록 구현된 애플리케이션
- 프로듀서와 마찬가지로 다양한 오픈소스 소프트웨어가 존재 (Apache Spark, Apache Samza ...)

**주키퍼**

- 카프카의 브로커에 있어 분산 처리를 위한 관리 도구로 아파치 주키퍼가 필요함
- 주키퍼는 하둡 등 병렬 분산 처리용 OSS에 있어서 설정 관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용됨

**카프카 클라이언트**

- 토픽 작성 등 카프카의 동작 및 운영 상에 필요한 조작을 실행하는 서버, 브로커랑 다름

**카프카 클러스터**

- 카프카의 여러대의 브로커 서버, 주키퍼 서버로 이루어진 클러스터링의 메시지 중계 기능과 메시지 송수신을 위한 라이브러리 그룹으로 구성됨. 브로커, 주키퍼에 의해 구성된 클러스터 시스템을 카프카 클러스터라고 정의



## 분산 메시징을 위한 구조

**파티션**

- 토픽에 대한 대량의 메시지 입출력을 지원하기 위해 브로커상의 데이터를 읽고 쓰는 것은 파티션이라는 단위로 분할되어 있음
- 토픽을 구성하는 파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서의 메시지 수신, 컨슈머로의 배달을 분산해서 실시함으로써 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원함
- 이런 파티션 정보는 브로커에 저장되기 때문에 실제 구현에서 파티션을 의식할 필요가 없음

**컨슈머 그룹**

- 카프카는 컨슈머에서 분산 스트림 처리도 고려해 설계되었기때문에 단일 애플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득하는 방법으로 컨슈머 그룹이라는 개념이 존재함
- 카프카 클러스터 전체에서 글로벌 ID를 컨슈머 그룹 전체에서 공유하고 여러 컨슈머는 자신이 속한 컨슈머 그룹을 식별해서 읽어들일 파티션을 분류하고 재시도를 제어함

**오프셋**

- 각 파티션에서 수신한 메시지에는 각각 일련번호가 부여되어 있어 파티션 단위로 메시지 위치를 나타내는 오프셋이라는 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위 및 재시도를 제어함 
- 제어에 사용되는 오프셋
  - Log-End-Offset(LEO) : 파티션 데이터의 끝을 나타냄
  - Current Offset: 컨슈머가 어디까지 메시지를 읽었는가를 나타냄
  - Commit Offset: 컨슈머가 어디까지 커밋했는지를 나타냄

### 메시지 송수신

- 카프가는 어느정도 메시지를 축적하여 배치 처리로 송수신하는 기능 또한 제공함

**프로듀서의 메시지 송신**

- 프로듀서가 토픽의 파티션에 메시지를 송신할 때 버퍼 기능처럼 프로듀서의 메모리를 이용하여 일정량을 축적 후 송신 가능
- 데이터 송신은 지정한 크기까지 메시지가 축적되거나 지정한 대기시간에 도달하는 것 중 하나를 트리거로 전송
- 기본설정은 1개씩 송신하지만 위에 설명한 배치처리로 성능향상 가능

**컨슈머의 메시지 취득**

- 컨슈머는 취득 대상의 토픽과 파티션에 대해 Current Offset으로 나타나는 위치에서 취득한 메시지 부터 브로커에서 보관하는 최신 메시지까지 모아서 요청 및 취득을 실시함
- 컨슈머도 통해 한번에 1개 또는 5개 등의 처리를 할 수 있음
- 프로듀서 컨슈머 모두 메시지를 모아서 처리할 수 있지만 충분한 고려와 설계가 필요함

### 컨슈머의 롤백

- 컨슈머는 메시지를 취득하고 오프셋을 지속적으로 업데이트하고 Offset commit을 통해 컨슈머 처리 실패, 고장시 롤 백 메시지 재취득을 실현함
- 컨슈머가 메시지를 소비하고 Offset Commit을 하기 이전에 장애가 나서 Offset Commit에 실패하여도 Offset Commit을 통해 메시지 상실을 방지할 수 있음

### 메시지 전송시 파티셔닝

- 프로듀서에서 송신하는 메시지를 어떻게 파티션으로 보낼지 결정하는 파티셔닝 기능이 제공됨
- **Key의 해시값을 사용한 송신: **메시지의 Key를 명시적으로 지정함으로써 Key에 따라 송신처 파티션을 결정하는 로직이됨 동일한 Key를 가지는 메시지는 동일한 ID를 가진 파티션에 송신됨
- **라운드 로빈에 의한 송신:** 메시지 Key를 지정하지 않고 Null로 한 경우 여러 파티션으로의 메시지 송신을 라운드 로빈 방식으로 실행함
- 파티셔닝을 이용하는 경우 데이터 편차에 따른 파티션의 편향에도 주의해야함



## 데이터의 견고성을 높이는 복제 구조

- 카프카는 메시지를 중계함과 동시에 서버가 고장 났을때 수신한 메시지를 잃지 안힉 위해서 복제 구조를 갖추고 있음
- 파티션은 단일 또는 여러개의 레플리카로 구성되고 여러 레플리카 중 한개는 Leader이며 나머지는 Follower임

### 레플리카의 동기 상태

- Leader 레플리카의 복제 상태를 유지하고 있는 레플리카는 In-Sync Replica로 분류됨 ISR 로 표기
- 모든 레플리카가 ISR로 되어 있지 않은 파티션을 Under Replicated Partitions라고 함
- 복제 수와는 독립적으로 최소 ISR 수 설정이 가능
- ISR 들은 비동기로 계속적으로 복제를 유지함

### 복제 완료 최신 오프셋(High Watermark)

- 복제 사용시 High Watermark 라는 개념이 있는데 이는 복제가 완료된 오프셋이고 컨슈머는 High Watermark 까지 기록된 메시지를 취득 가능함

### 프로듀서의 메시지 도달 보증 수준

- 브로커에서 프로듀서로 메시지 송신 여부를 나타내는 Ack 를 어느 타이밍에 송신할 것인지를 제어하는 것은 성능과 내장애성에 큰 영향을 줌 ack는 3종류로 설정 가능
  - 0: 프로듀서는 메시지 송신시 Ack를 기다리지 않고 다음 메시지를 송신
  - 1: Leader Replica에 메시지가 전달되면 Ack를 반환함
  - all: 모든 ISR의 수만큼 복제되면 Ack를 반환함
- 프로듀서는 타임아웃 설정으로 Ack가 돌아오지 않은 Send를 송신 실패로 감지함



### ISR과 Ack =all, 쓰기 계속성의 관계

- 



## 정리

- 스케일 아웃 구성

  - 메시지를 중계하는 브로커를 여러 대 구성할 수 있으며, 브로커 수를 증가함으로써 클러스터 전체의 처리량을 증가시킬 수 있음

- 데이터의 디스크 영속화

  - 브로커에서 수신한 메시지는 디스크에 기록되어 영속화됨. 디스크 용량에 따라 장기간의 과거 데이터를 저장 재취득 가능

- 연계할 수 있는 제품 존재

  - 프로듀서/컨슈머를 구현하기 위한 API가 제공되어 이를 구현한 OSS가 많이 존재함

- 메시지 도달 보증

  - Ack와 Offset Commit 방식으로 메시지가 제대로 송수신 되었음을 확인하고 실패시 재시도를 허용함

  

# #3장 카프카 설치

- 카프카 설치는 책 또는 인터넷 검색으로 참고해서 설치

- confluent.repo

```
[Confluent.dist]
name=Confluent repository (dist)
baseurl=https://packages.confluent.io/rpm/5.0/7
gpgcheck=1
gpgkey=https://packages.confluent.io/rpm/5.0/archive.key

[Confluent]
name=Confluent repository
baseurl=https://packages.confluent.io/rpm/5.0
gpgcheck=1
gpgkey=https://packages.confluent.io/rpm/5.0/archive.key
endable=1
```

**설치**

```
sudo rpm --import https://pakcages.confluent.io.rpm/5.0/archive.key
위에 repo /etc/yum.repo.d/ 에 저장
yum clean all
sudo yum install confluent-platform-oss-2.11
sudo systemctl start confluent-zookeeper
sudo systemctl start confluent-kafka
```



**topic 생성**

```
kafka-topics --zookeeper localhost:2181 --create --topic first-test --partitions 3 --replication-factor 1
```

- --zookeeper : 카프카 클러스터를 관리하고 있는 주키퍼로의 접속 정보를 지정함 이 정보는 /etc/kafka/server.properties에 있음 n개열경우 쉼표로 지정
- --create: 토픽을 작성함 --create 외에 토픽의 목록을 확인하는 --list 삭제하는 --delete 등이 있음
- --topic: 작성하는 토픽의 이름을 지정함. 여기에서는 토픽의 이름으로 first-test를 사용함 토픽의 이름엔 -와 .를 사용하지 않음
- --partitions: 작성하는 토픽의 파티션 수를 지정함 
- --replication-factor: 작성하는 토픽의 레플리카의 수를 지정함 이 수는 카프카 클러스터에서 브로커의 수보다 많을 수 없음 브로커가 1개라면 최대설정값이 1개임



**topic 확인**

```
kafka-topics --zookeeper localhost:2181 --describe --topic first-test
```

- Leader : 각 파티션의 현재 Leader Replica가 어떤 브로커에 존재하고 있는지 표시함 여기에 표시되는 번호는 각 브로커에 설정한 브로커 ID 임
- Replicas: 각 파티션의 레플리카를 보유하고 있는 브로커의 목록 표시
- Isr: In-Sync Replicas 레플리카 중 Leader Replica와 올바르게 동기가 실행된 복제본을 보유하고 있는 브로커 목록 장애가 발생하고 있는 브로커를 보유하고 있거나 특정 이유로 Leader Replica의 동기화가 실행되지 않는다면 Isr에 포함되지 않음 Leader Replica는 Isr에 포함됨



**Kafka Console Producer 사용하기**

```
kafka-console-producer --broker-list localhost:9092 --topic first-test
```

- --broker-list: 메시지를 보내는 카프카 클러스터의 브로커 호스트명과 포트 번호를 지정함 여러개가 있을 경우 쉼표로 구분 카프카가 통신에 사용하는 포트의 기본값은 9092임
- --topic 메시지 송신처가 되는 토픽을 지정

**Kafka Console Consumer 사용하기**

```
kafka-console-consumer --bootstrap-server localhost:9092 --topic first-test
```

- --bootstrap-server: 메시지를 수신하는 카프카 클러스터의 브로커 호스트명과 포트번호를 지정 위에 --broker-list와 동일
- --topic 메시지 송신처가 되는 토픽을 지정



# #4 자바 API를 사용하여 애플리케이션 만들기

## Kafka Producer 만들기

- 의존성 (컨플루언트가 제공하는 kafka 라이브러리임)

```
  <repositories>
    <repository>
      <id>confluent</id>
      <url>https://packages.confluent.io/maven/</url>
    </repository>
  </repositories>
  
  ..
  
  <dependencies>
    <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka_2.11</artifactId>
      <version>2.0.0-cp1</version>
    </dependency>
  </dependencies>

```

- KafkaProducer.java

```java
    // 1. KafkaProducer에 필요한 설정
    Properties conf = new Properties();
    conf.setProperty("bootstrap.servers", "localhost:9092");
    conf.setProperty("key.serializer", "org.apache.kafka.common.serialization.IntegerSerializer");
    conf.setProperty("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
```
- bootstrap.servers: kafkaProducer가 접근할 브로커의 호스트명과 포트명 topic 생성시에 --broker-list와 동일함
- key.serializer, value,serializer: 카프카에서는 모든 메시지가 직렬화된 상태로 전송됨. 이 직렬화 처리에 이용되는 시리얼라이저 클래스를 지정함 카프카는 기본 자료형에 대한 시리얼라이즈를 다양하게 제공하고 있음



```java

        // 2. Kafka 클러스터에 메시지를 송신(produce)하는 객체를 생성
        Producer<Integer, String> producer = new KafkaProducer<>(conf);

```

- config를 통해서 Producer 객체 생성



```java
            // 3. 송신할 메시지를 생성
            ProducerRecord<Integer, String> record = new ProducerRecord<>(topicName, key, value);
```

-  ProducerRecode를 통해서 레코드 생성

```java
            // 4. 메시지를 송신하고, Ack을 받았을 때에 실행할 작업(Callback)을 등록한다
            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception e) {
                    if( metadata != null) {
                        // 송신에 성공한 경우의 처리
                        String infoString = String.format("Success partition:%d, offset:%d", metadata.partition(), metadata.offset());
                        System.out.println(infoString);
                    } else {
                        // 송신에 실패한 경우의 처리
                        String infoString = String.format("Failed:%s", e.getMessage());
                        System.err.println(infoString);
                    }
                }
            });
```

- Callback 클래스를 통해서 메시지 전송 이후 동작할 콜백메서드를 지정함
- KafkaProducer는 송신 처리를 비동기로 하기 때문에 콜백 메서드를 통한 Ack 여부를 확인할 수 있음

```java
    // 5. KafkaProducer를 클로즈하여 종료
    producer.close();
```


## Kafka Consumer 만들기

```java
        // 1. KafkaConsumer에 필요한 설정
        Properties conf = new Properties();
        conf.setProperty("bootstrap.servers", "kafka-broker01:9092,kafka-broker02:9092,kafka-broker03:9092");
        conf.setProperty("group.id", "FirstAppConsumerGroup");
        conf.setProperty("enable.auto.commit", "false");
        conf.setProperty("key.deserializer", "org.apache.kafka.common.serialization.IntegerDeserializer");
        conf.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

```

- bootstrap.servers: 접속할 브로커의 호스트명과 포트번호
- groupid: 작성할 KafkaConsumer가 속한 Consumer Group 지정
- enable.auto.commit: 오프셋 커밋을 자동으로 실행할지의 여부
- key.deserializer, value.deserializer: 컨슈머에서 디시리얼라이즈 하는 클래스를 지정 프로듀서와 일치해야함

```java
        // 2. Kafka클러스터에서 Message를 수신(Consume)하는 객체를 생성
        Consumer<Integer, String> consumer = new KafkaConsumer<>(conf);
        // 3. 수신(subscribe)하는 Topic을 등록
        consumer.subscribe(Collections.singletonList(topicName));

```

- 프로듀서 어플리케이션과 동일한 Key Value를 가지는 Consumer객체를 생성해서 구독하도록 지정



```java
            // 4. Message를 수신하여, 콘솔에 표시한다
            ConsumerRecords<Integer, String> records = consumer.poll(1);
            
            ...
            
                // 5. 처리가 완료한 Message의 Offset을 Commit한다
                TopicPartition tp = new TopicPartition(record.topic(), record.partition());
                OffsetAndMetadata oam = new OffsetAndMetadata(record.offset() + 1);
                Map<TopicPartition, OffsetAndMetadata> commitInfo = Collections.singletonMap(tp, oam);
                consumer.commitSync(commitInfo);
```

- KafkaConsumer는 카프카 클러스터에서 메시지를 얻을 때 설정된 상한의 범위 내에서 여러 메시지를 취득함 그 다음 사용자에게 한번의 poll로 전달해도 좋다는 메시지 양의 상한까지 ConsumerRecodes에 메시지를 포함하여 전달함 설정가능
- 오프셋 커밋을 자동으로하지않고 수동으로 설정하면 5번처럼 할 수 있는데 여기에서는 하나의 메시지가 처리할때마다 오프셋을 한개씩 늘려서 커밋하고 있음
- 오프셋 커밋의 빈도는 컨슈머 애플리케이션에 장애 등이 발생했을 때에 동일 메시지의 재 처리를 어느정도 허용할 수 있는지에 따라 달라짐
- 오프셋 커밋시 commitSync라는 메서드를 사용하는데 비동기로 처리하려면 commitAsync를 사용하면 됨 commitSync는 말그대로 블로킹처리임



```java
    // 6. KafkaConsumer를 클로즈하여 종료
    consumer.close();
```




# #5 카프카 적용 사례

## 카프카 적용 사례

### 카프카 대표적인 기능

- 메시지 큐 제품/로그 수집 제품/ETL 도구 등 예전부터 존재했던 몇몇 제품의 대체

**카프카의 대표적인 기능 5가지**

1. 데이터 허브
   - 여러 시스템 사이에서 데이터를 상호 교환함
2. 로그 수집
   - BI 도구를 이용한 리포팅과 인공지능 분석을 위해 여러 서버에서 생성된 로그를 수집하고 축적할 곳에 연결
3. 웹 활동 분석
   - 실시간 대시보드와 이상 탐지/부정 검출등 웹에서의 사용자 활동을 실시간으로 파악
4. 사물인터넷
   - 센서 등 다양한 디바이스에서 보낸 데이터를 수신해서 처리한 후 디바이스에 송신
5. 이벤트 소싱
   - 데이터에 대한 일련의 이벤트를 순차적으로 기록하고 CQRS(Command Query Responsibility Segregation : 읽기 및 쓰기 아키텍처를 분리하여 취급하는 개념) 방식으로 대량의 이벤트를 유연하게 처리

### 카프카 특징 복습

- 카프카는 대량의 데이터를 높은 처리량으로 실시간 처리하기 위한 제품
- 카프카는 데이터를 전달하는 파이프라인 그 자체를 구성하기 위한 기반이라고 말할 수 있을 정도의 개념까지 올라옴
- 카프카로 실현할 수 있는 4가지
  1. 확장성: 여러 서버로 확장 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장이 가능
  2. 영속성: 수신한 데이터를 디스크에 유지할 수 있기 때문에 언제라도 데이터를 읽을 수 있음
  3. 유연성: 연계할 수 있는 제품이 많기 때문에 제품이나 시스템을 연결하는 허브 역할을 함
  4. 신뢰성: 메시지 전달 보증을 하므로 데이터 분실을 걱정하지 않아도됨
- 카프카의 각 기능과 특징이 중시되는 상황
  - 실시간: 긴급성이 요구되거나 데이터를 즉시 사용하는 경우
  - 동보 전송: 하나의 동일한 데이터를 후속의 여러 시스템에서 사용하는 경우 데이터를 전달하는 관계 시스템이 단계적으로 증가하는 경우
  - 영속성: 데이터를 버퍼링해야 하는 경우나 처리 시간 간격이 다른 복수의 처리와 관련된 경우
  - 다수의 제휴 제품: 사용되는 제품이 균일하지 않고 다양한 접속을 필요로 하는 경우
  - 송수신 보증: 데이터 손실이 허용되지 않는 경우
  - 순서 보증: 데이터 소스에 있어 데이터의 생성 순서를 중시하여 순서에 따른 판단과 제어를 수반하는 경우 

### 카프카 특징과 사례 대응

| 사례         | 실시간 | 동보전송 | 영속성 | 다수의 제휴 제품 | 송수신 보증 | 순서 보증 |
| ------------ | ------ | -------- | ------ | ---------------- | ----------- | --------- |
| 데이터허브   |        | O        | O      | O                | O           |           |
| 로그 수집    |        |          | O      | O                | O           |           |
| 웹 활동 분석 | O      |          |        | O                | O           | O         |
| 사물 인터넷  | O      |          |        | O                |             |           |
| 이벤트 소싱  | O      |          | O      |                  | O           | O         |





## 데이터 허브

- 데이터 허브는 여러 곳의 데이터 소스가 되는 시스템에서 데이터를 수집하여 여러 시스템에 전달하는 아키텍처

### 데이터 허브에서 해결해야할 과제

- 데이터를 생산하는 자가 직접 송신처와 데이터를 주고 받다보면 시간이 지날수록 결합도가 증가하게됨 ex 새롭게 추가되는 수신처의 새로운 프로토콜을 생산자와 송신처에 둘다 적용해야한다는점 .. 등등 
- 이런 시스템이 분리되어 시스템 간의 연계를 효율적으로 할 수 없는 상황을 사일로화 됐다고함
- 시스템 사일로화에 의한 증가에 따라 다음과 같은 과제를 해결해야함
  1. 데이터 소스에서 생성된 동일한 데이터를 여러 시스템에서 이용함
  2. 후속 시스템마다 데이터를 필요로 하는 시기와 빈도가 다름
  3. 접속원이나 연결 시스템에서 이용되는 연계 방식이 제각각임
  4. 데이터분실을 허용하지 않음



### 카프카로 데이터 허브 구현하기

- 



### 











